{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8yBkNmLleQHT5nLZbFbaR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pieper/Notebooks/blob/master/auto3dseg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From: https://github.com/Project-MONAI/tutorials/blob/main/auto3dseg/notebooks/auto3dseg_hello_world.ipynb"
      ],
      "metadata": {
        "id": "XlwddIYOmcZ7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuYo9MbxmIpS",
        "outputId": "d3147168-e55c-40c9-f635-7a03b1c7f5bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "ModuleNotFoundError: No module named 'monai'\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 7.1 MB/s \n",
            "\u001b[?25hTraceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "ModuleNotFoundError: No module named 'einops'\n"
          ]
        }
      ],
      "source": [
        "!python -c \"import monai\" || pip install -q \"monai-weekly[nibabel]\"\n",
        "\n",
        "!python -c \"import einops\" || pip install -q \"einops\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deps = [\"nibabel\", \"skimage\", \"pillow\", \"tensorboard\", \"gdown\", \"ignite\", \"torchvision\", \"itk\", \"tqdm\", \"lmdb\", \"psutil\", \"cucim\", \"openslide\", \"pandas\", \"einops\", \"transformers\", \"mlflow\", \"matplotlib\", \"tensorboardX\", \"tifffile\", \"imagecodecs\", \"pyyaml\", \"fire\", \"jsonschema\", \"pynrrd\", \"pydicom\", \"h5py\", \"nni\", \"optuna\"]\n",
        "for dep in deps:\n",
        "  try:\n",
        "    import dep\n",
        "  except ModuleNotFoundError:\n",
        "    import pip\n",
        "    pip.main([\"install\", dep])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne0jJwFpnDnl",
        "outputId": "c9b00e5b-c2c3-4a4d-bc62-c21718da8f8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.7/dist-packages (3.0.2)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from nibabel) (1.21.6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting skimage\n",
            "  Downloading skimage-0.0.tar.gz (757 bytes)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Discarding https://files.pythonhosted.org/packages/3b/ee/edbfa69ba7b7d9726e634bfbeefd04b5a1764e9e74867ec916113eeaf4a1/skimage-0.0.tar.gz#sha256=6c96a11d9deea68489c9b80b38fad1dcdab582c36d4fa093b99b24a3b30c38ec (from https://pypi.org/simple/skimage/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\n",
            "ERROR: Could not find a version that satisfies the requirement skimage (from versions: 0.0)\n",
            "ERROR: No matching distribution found for skimage\n",
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.21.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.37.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.8.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.2.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (57.4.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.17.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.35.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.48.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.6.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ignite\n",
            "  Downloading ignite-1.1.0-py2.py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.7/dist-packages (from ignite) (1.14.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ignite) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ignite) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ignite) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ignite) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ignite) (3.0.4)\n",
            "Installing collected packages: ignite\n",
            "Successfully installed ignite-1.1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision) (4.1.1)\n",
            "Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.12.1+cu113)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting itk\n",
            "  Downloading itk-5.2.1.post1-cp37-cp37m-manylinux2014_x86_64.whl (8.3 kB)\n",
            "Collecting itk-io==5.2.1.post1\n",
            "  Downloading itk_io-5.2.1.post1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.0 MB)\n",
            "Collecting itk-registration==5.2.1.post1\n",
            "  Downloading itk_registration-5.2.1.post1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.3 MB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from itk) (1.21.6)\n",
            "Collecting itk-filtering==5.2.1.post1\n",
            "  Downloading itk_filtering-5.2.1.post1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (95.3 MB)\n",
            "Collecting itk-core==5.2.1.post1\n",
            "  Downloading itk_core-5.2.1.post1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (70.6 MB)\n",
            "Collecting itk-numerics==5.2.1.post1\n",
            "  Downloading itk_numerics-5.2.1.post1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (54.5 MB)\n",
            "Collecting itk-segmentation==5.2.1.post1\n",
            "  Downloading itk_segmentation-5.2.1.post1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.6 MB)\n",
            "Installing collected packages: itk-core, itk-numerics, itk-filtering, itk-segmentation, itk-registration, itk-io, itk\n",
            "Successfully installed itk-5.2.1.post1 itk-core-5.2.1.post1 itk-filtering-5.2.1.post1 itk-io-5.2.1.post1 itk-numerics-5.2.1.post1 itk-registration-5.2.1.post1 itk-segmentation-5.2.1.post1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.7/dist-packages (0.99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cucim\n",
            "  Downloading cucim-22.8.1-py3-none-manylinux2014_x86_64.whl (8.6 MB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from cucim) (1.21.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from cucim) (7.1.2)\n",
            "Installing collected packages: cucim\n",
            "Successfully installed cucim-22.8.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement openslide (from versions: none)\n",
            "ERROR: No matching distribution found for openslide\n",
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.2.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (0.5.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.22.2-py3-none-any.whl (4.9 MB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting huggingface-hub<1.0,>=0.9.0\n",
            "  Downloading huggingface_hub-0.10.0-py3-none-any.whl (163 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.0 tokenizers-0.12.1 transformers-4.22.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mlflow\n",
            "  Downloading mlflow-1.29.0-py3-none-any.whl (16.9 MB)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.21.6)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.4.2)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.7.3)\n",
            "Requirement already satisfied: pytz<2023 in /usr/local/lib/python3.7/dist-packages (from mlflow) (2022.2.1)\n",
            "Collecting databricks-cli<1,>=0.8.7\n",
            "  Downloading databricks-cli-0.17.3.tar.gz (77 kB)\n",
            "Requirement already satisfied: cloudpickle<3 in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.5.0)\n",
            "Requirement already satisfied: packaging<22 in /usr/local/lib/python3.7/dist-packages (from mlflow) (21.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (7.1.2)\n",
            "Requirement already satisfied: pandas<2 in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.3.5)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.7/dist-packages (from mlflow) (6.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (3.17.3)\n",
            "Collecting querystring-parser<2\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Collecting prometheus-flask-exporter<1\n",
            "  Downloading prometheus_flask_exporter-0.20.3-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: entrypoints<1 in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.4)\n",
            "Collecting gunicorn<21\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "Collecting alembic<2\n",
            "  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\n",
            "Requirement already satisfied: sqlalchemy<2,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.4.41)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<5,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (4.12.0)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.7/dist-packages (from mlflow) (2.23.0)\n",
            "Collecting docker<7,>=4.0.0\n",
            "  Downloading docker-6.0.0-py3-none-any.whl (147 kB)\n",
            "Collecting gitpython<4,>=2.1.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "Requirement already satisfied: Flask<3 in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.1.4)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic<2->mlflow) (5.9.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.3-py3-none-any.whl (78 kB)\n",
            "Collecting pyjwt>=1.7.0\n",
            "  Downloading PyJWT-2.5.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (3.2.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (0.8.10)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.15.0)\n",
            "Collecting urllib3>=1.26.0\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "Collecting requests<3,>=2.17.3\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.4.1-py3-none-any.whl (55 kB)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask<3->mlflow) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask<3->mlflow) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask<3->mlflow) (2.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from gitpython<4,>=2.1.0->mlflow) (4.1.1)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.7/dist-packages (from gunicorn<21->mlflow) (57.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata!=4.7.0,<5,>=3.7.0->mlflow) (3.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask<3->mlflow) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging<22->mlflow) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2->mlflow) (2.8.2)\n",
            "Collecting prometheus-client\n",
            "  Downloading prometheus_client-0.14.1-py3-none-any.whl (59 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.17.3->mlflow) (2022.6.15)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.17.3->mlflow) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.17.3->mlflow) (2.10)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy<2,>=1.4.0->mlflow) (1.1.3)\n",
            "Building wheels for collected packages: databricks-cli\n",
            "  Building wheel for databricks-cli (setup.py): started\n",
            "  Building wheel for databricks-cli (setup.py): finished with status 'done'\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.17.3-py3-none-any.whl size=139102 sha256=fdf329756c0ac79888935db6e50aac81c42fdd80b27b4cdd8f01d17761b2ddea\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/73/87/c1e4b2145eb6049bb6c9aaf7ea1e38302b77ca219b6fef5d5c\n",
            "Successfully built databricks-cli\n",
            "Installing collected packages: urllib3, smmap, websocket-client, requests, pyjwt, prometheus-client, Mako, gitdb, querystring-parser, prometheus-flask-exporter, gunicorn, gitpython, docker, databricks-cli, alembic, mlflow\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "Successfully installed Mako-1.2.3 alembic-1.8.1 databricks-cli-0.17.3 docker-6.0.0 gitdb-4.0.9 gitpython-3.1.27 gunicorn-20.1.0 mlflow-1.29.0 prometheus-client-0.14.1 prometheus-flask-exporter-0.20.3 pyjwt-2.5.0 querystring-parser-1.2.4 requests-2.28.1 smmap-5.0.0 urllib3-1.26.12 websocket-client-1.4.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.5.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.7/dist-packages (2021.11.2)\n",
            "Requirement already satisfied: numpy>=1.15.1 in /usr/local/lib/python3.7/dist-packages (from tifffile) (1.21.6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting imagecodecs\n",
            "  Downloading imagecodecs-2021.11.20-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.0 MB)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from imagecodecs) (1.21.6)\n",
            "Installing collected packages: imagecodecs\n",
            "Successfully installed imagecodecs-2021.11.20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (6.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fire\n",
            "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire) (1.1.0)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py): started\n",
            "  Building wheel for fire (setup.py): finished with status 'done'\n",
            "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115942 sha256=9c98942bb028c006f989be8481f487b8cc883d04782733a5ac32379e7d0da84d\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
            "Successfully built fire\n",
            "Installing collected packages: fire\n",
            "Successfully installed fire-0.4.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (4.3.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema) (4.12.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema) (0.18.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema) (4.1.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema) (5.9.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema) (22.1.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema) (3.8.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pynrrd\n",
            "  Downloading pynrrd-0.4.3-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from pynrrd) (1.21.6)\n",
            "Installing collected packages: pynrrd\n",
            "Successfully installed pynrrd-0.4.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pydicom\n",
            "  Downloading pydicom-2.3.0-py3-none-any.whl (2.0 MB)\n",
            "Installing collected packages: pydicom\n",
            "Successfully installed pydicom-2.3.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.21.6)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nni\n",
            "  Downloading nni-2.9-py3-none-manylinux1_x86_64.whl (56.0 MB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from nni) (21.3)\n",
            "Requirement already satisfied: scipy<1.8 in /usr/local/lib/python3.7/dist-packages (from nni) (1.7.3)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Collecting PythonWebHDFS\n",
            "  Downloading PythonWebHDFS-0.2.3-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from nni) (1.3.5)\n",
            "Requirement already satisfied: numpy<1.22 in /usr/local/lib/python3.7/dist-packages (from nni) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from nni) (3.8.0)\n",
            "Requirement already satisfied: hyperopt==0.1.2 in /usr/local/lib/python3.7/dist-packages (from nni) (0.1.2)\n",
            "Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.7/dist-packages (from nni) (1.0.2)\n",
            "Collecting websockets>=10.1\n",
            "  Downloading websockets-10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (112 kB)\n",
            "Requirement already satisfied: pyyaml>=5.4 in /usr/local/lib/python3.7/dist-packages (from nni) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from nni) (4.1.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from nni) (5.4.8)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.7/dist-packages (from nni) (2.7.1)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from nni) (0.8.1)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.7/dist-packages (from nni) (3.4.1)\n",
            "Collecting schema\n",
            "  Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
            "Collecting json-tricks>=3.15.5\n",
            "  Downloading json_tricks-3.15.5-py2.py3-none-any.whl (26 kB)\n",
            "Collecting responses\n",
            "  Downloading responses-0.21.0-py3-none-any.whl (45 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nni) (4.64.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from nni) (1.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from nni) (2.23.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.1.2->nni) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.1.2->nni) (1.15.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.1.2->nni) (4.2.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.1.2->nni) (2.6.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.1->nni) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.1->nni) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->nni) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->nni) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->nni) (2022.2.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable->nni) (0.2.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from prettytable->nni) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->prettytable->nni) (3.8.1)\n",
            "Collecting simplejson\n",
            "  Downloading simplejson-3.17.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (130 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->nni) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->nni) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->nni) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->nni) (3.0.4)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "Requirement already satisfied: contextlib2>=0.5.5 in /usr/local/lib/python3.7/dist-packages (from schema->nni) (0.5.5)\n",
            "Installing collected packages: urllib3, simplejson, websockets, schema, responses, PythonWebHDFS, json-tricks, colorama, nni\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Can't uninstall 'urllib3'. No files were found to uninstall.\n",
            "Successfully installed PythonWebHDFS-0.2.3 colorama-0.4.5 json-tricks-3.15.5 nni-2.9 responses-0.21.0 schema-0.7.5 simplejson-3.17.6 urllib3-1.26.12 websockets-10.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.0.2-py3-none-any.whl (348 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Requirement already satisfied: scipy<1.9.0,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.3)\n",
            "Collecting alembic>=1.5.0\n",
            "  Using cached alembic-1.8.1-py3-none-any.whl (209 kB)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.41)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (4.12.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (5.9.0)\n",
            "Collecting Mako\n",
            "  Using cached Mako-1.2.3-py3-none-any.whl (78 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.3.0->optuna) (1.1.3)\n",
            "Collecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.10.0-py2.py3-none-any.whl (112 kB)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "Collecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.4.1)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (4.1.1)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py): started\n",
            "  Building wheel for pyperclip (setup.py): finished with status 'done'\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=eed5b0c2a623f4138c7fd288e40a607314c3cb0aea6cb2d441b95d95fd63e2ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.3 alembic-1.8.1 autopage-0.5.1 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.2 colorlog-6.7.0 optuna-3.0.2 pbr-5.10.0 pyperclip-1.8.2 stevedore-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from monai.apps.auto3dseg import AutoRunner\n",
        "from monai.data import create_test_image_3d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nq3Mu1tImRaz",
        "outputId": "0d24c853-5a50-4c61-b979-79322e5cb520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumExpr defaulting to 2 threads.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sim_datalist = {\n",
        "    \"testing\": [\n",
        "        {\"image\": \"test_image_001.nii.gz\", \"label\": \"test_label_001.nii.gz\"},\n",
        "        {\"image\": \"test_image_002.nii.gz\", \"label\": \"test_label_002.nii.gz\"},\n",
        "    ],\n",
        "    \"training\": [\n",
        "        {\"fold\": 0, \"image\": \"tr_image_001.nii.gz\", \"label\": \"tr_label_001.nii.gz\"},\n",
        "        {\"fold\": 0, \"image\": \"tr_image_002.nii.gz\", \"label\": \"tr_label_002.nii.gz\"},\n",
        "        {\"fold\": 0, \"image\": \"tr_image_003.nii.gz\", \"label\": \"tr_label_003.nii.gz\"},\n",
        "        {\"fold\": 0, \"image\": \"tr_image_004.nii.gz\", \"label\": \"tr_label_004.nii.gz\"},\n",
        "        {\"fold\": 1, \"image\": \"tr_image_005.nii.gz\", \"label\": \"tr_label_005.nii.gz\"},\n",
        "        {\"fold\": 1, \"image\": \"tr_image_006.nii.gz\", \"label\": \"tr_label_006.nii.gz\"},\n",
        "        {\"fold\": 1, \"image\": \"tr_image_007.nii.gz\", \"label\": \"tr_label_007.nii.gz\"},\n",
        "        {\"fold\": 1, \"image\": \"tr_image_008.nii.gz\", \"label\": \"tr_label_008.nii.gz\"},\n",
        "        {\"fold\": 2, \"image\": \"tr_image_009.nii.gz\", \"label\": \"tr_label_009.nii.gz\"},\n",
        "        {\"fold\": 2, \"image\": \"tr_image_010.nii.gz\", \"label\": \"tr_label_010.nii.gz\"},\n",
        "        {\"fold\": 2, \"image\": \"tr_image_011.nii.gz\", \"label\": \"tr_label_011.nii.gz\"},\n",
        "        {\"fold\": 2, \"image\": \"tr_image_012.nii.gz\", \"label\": \"tr_label_012.nii.gz\"},\n",
        "    ],\n",
        "}\n",
        "\n",
        "sim_dim = (64, 64, 64)"
      ],
      "metadata": {
        "id": "VZXxLSXWmWpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "work_dir = \"./helloworld_work_dir\"\n",
        "if not os.path.isdir(work_dir):\n",
        "    os.makedirs(work_dir)\n",
        "\n",
        "dataroot_dir = os.path.join(work_dir, \"sim_dataroot\")\n",
        "if not os.path.isdir(dataroot_dir):\n",
        "    os.makedirs(dataroot_dir)\n",
        "\n",
        "datalist_file = os.path.join(work_dir, \"sim_datalist.json\")\n",
        "with open(datalist_file, 'w') as f:\n",
        "    json.dump(sim_datalist, f)\n",
        "\n",
        "for d in sim_datalist[\"testing\"] + sim_datalist[\"training\"]:\n",
        "    im, seg = create_test_image_3d(\n",
        "        sim_dim[0], sim_dim[1], sim_dim[2], rad_max=10, num_seg_classes=1, random_state=np.random.RandomState(42)\n",
        "    )\n",
        "    image_fpath = os.path.join(dataroot_dir, d[\"image\"])\n",
        "    label_fpath = os.path.join(dataroot_dir, d[\"label\"])\n",
        "    nib.save(nib.Nifti1Image(im, affine=np.eye(4)), image_fpath)\n",
        "    nib.save(nib.Nifti1Image(seg, affine=np.eye(4)), label_fpath)"
      ],
      "metadata": {
        "id": "MUovJBZVma-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_nib = nib.load(os.path.join(dataroot_dir, sim_datalist['testing'][0]['image']))\n",
        "lbl_nib = nib.load(os.path.join(dataroot_dir, sim_datalist['testing'][0]['label']))\n",
        "img = np.array(img_nib.dataobj)\n",
        "lbl = np.array(lbl_nib.dataobj)\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(img[32])\n",
        "plt.title('image')\n",
        "cbar = plt.colorbar(shrink=0.55)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(lbl[32])\n",
        "plt.title('label')\n",
        "cbar = plt.colorbar(shrink=0.55)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "NPCo8DqJmkaK",
        "outputId": "c8382b1c-66a0-4b6e-9b2c-587cdecfa61d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "runner = AutoRunner(\n",
        "    work_dir=work_dir,\n",
        "    input={\n",
        "        \"modality\": \"MRI\",\n",
        "        \"datalist\": datalist_file,\n",
        "        \"dataroot\": dataroot_dir,\n",
        "    }\n",
        ")\n",
        "# runner.run() # this will use the default settings and take hours/ to run"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtFMHflJmnr6",
        "outputId": "e56d5291-dde2-41d0-e946-c5a1aaec1d1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-03 21:55:08,183 - INFO - Work directory ./helloworld_work_dir is used to save all results\n",
            "2022-10-03 21:55:08,190 - INFO - The output_dir is not specified. /content/helloworld_work_dir/ensemble_output will be used to save ensemble predictions\n",
            "2022-10-03 21:55:08,204 - INFO - Directory /content/helloworld_work_dir/ensemble_output is created to save ensemble predictions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_epochs = 2\n",
        "\n",
        "# safeguard to ensure max_epochs is greater or equal to 2\n",
        "max_epochs = max(max_epochs, 40)\n",
        "\n",
        "train_param = {\n",
        "    \"CUDA_VISIBLE_DEVICES\": [0],  # use only 1 gpu\n",
        "    \"num_iterations\": 4 * max_epochs,\n",
        "    \"num_iterations_per_validation\": 2 * max_epochs,\n",
        "    \"num_images_per_batch\": 2,\n",
        "    \"num_epochs\": max_epochs,\n",
        "    \"num_warmup_iterations\": 2 * max_epochs,\n",
        "}\n",
        "runner.set_training_params(train_param)\n",
        "runner.set_num_fold(num_fold=1)"
      ],
      "metadata": {
        "id": "UDpKTOy1msqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "runner.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4y1h-USdmzh1",
        "outputId": "15e5b7d8-8eb0-4602-86be-5f24da9fd535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "File /content/helloworld_work_dir/datastats.yaml already exists and will be overwritten.\n",
            "100%|██████████| 12/12 [00:00<00:00, 18.87it/s]\n",
            "algo_templates.tar.gz: 100%|██████████| 280k/280k [00:00<00:00, 751kB/s]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-03 22:00:17,802 - INFO - Downloaded: /tmp/tmp75o61lpp/algo_templates.tar.gz\n",
            "2022-10-03 22:00:17,805 - INFO - Expected md5 is None, skip md5 check for file /tmp/tmp75o61lpp/algo_templates.tar.gz.\n",
            "2022-10-03 22:00:17,807 - INFO - Writing into directory: /content/helloworld_work_dir.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-03 22:00:18,125 - INFO - /content/helloworld_work_dir/segresnet2d_0\n",
            "2022-10-03 22:00:18,439 - INFO - /content/helloworld_work_dir/dints_0\n",
            "2022-10-03 22:00:18,665 - INFO - /content/helloworld_work_dir/swinunetr_0\n",
            "2022-10-03 22:00:18,940 - INFO - /content/helloworld_work_dir/segresnet_0\n",
            "2022-10-03 22:00:18,945 - INFO - Launching: python /content/helloworld_work_dir/swinunetr_0/scripts/train.py run --config_file='/content/helloworld_work_dir/swinunetr_0/configs/transforms_train.yaml','/content/helloworld_work_dir/swinunetr_0/configs/transforms_infer.yaml','/content/helloworld_work_dir/swinunetr_0/configs/network.yaml','/content/helloworld_work_dir/swinunetr_0/configs/hyper_parameters.yaml','/content/helloworld_work_dir/swinunetr_0/configs/transforms_validate.yaml' --num_iterations=160 --num_iterations_per_validation=80 --num_images_per_batch=2 --num_epochs=40 --num_warmup_iterations=80\n",
            "2022-10-03 22:02:25,861 - INFO - CompletedProcess(args=['python', '/content/helloworld_work_dir/swinunetr_0/scripts/train.py', 'run', \"--config_file='/content/helloworld_work_dir/swinunetr_0/configs/transforms_train.yaml','/content/helloworld_work_dir/swinunetr_0/configs/transforms_infer.yaml','/content/helloworld_work_dir/swinunetr_0/configs/network.yaml','/content/helloworld_work_dir/swinunetr_0/configs/hyper_parameters.yaml','/content/helloworld_work_dir/swinunetr_0/configs/transforms_validate.yaml'\", '--num_iterations=160', '--num_iterations_per_validation=80', '--num_images_per_batch=2', '--num_epochs=40', '--num_warmup_iterations=80'], returncode=0, stdout=b\"[info] number of GPUs: 1\n",
            "[info] world_size: 1\n",
            "train_files: 8\n",
            "val_files: 4\n",
            "num_epochs 40\n",
            "num_epochs_per_validation 20\n",
            "[info] training from scratch\n",
            "[info] amp enabled\n",
            "----------\n",
            "epoch 1/40\n",
            "learning rate is set to 0.0001\n",
            "[2022-10-03 22:00:31] 1/4, train_loss: 1.2798\n",
            "[2022-10-03 22:00:32] 2/4, train_loss: 1.0854\n",
            "[2022-10-03 22:00:32] 3/4, train_loss: 0.9221\n",
            "[2022-10-03 22:00:33] 4/4, train_loss: 0.8098\n",
            "epoch 1 average loss: 1.0243, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 2/40\n",
            "learning rate is set to 0.0001\n",
            "[2022-10-03 22:00:34] 1/4, train_loss: 0.7463\n",
            "[2022-10-03 22:00:34] 2/4, train_loss: 0.6999\n",
            "[2022-10-03 22:00:35] 3/4, train_loss: 0.6610\n",
            "[2022-10-03 22:00:35] 4/4, train_loss: 0.6247\n",
            "epoch 2 average loss: 0.6830, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 3/40\n",
            "learning rate is set to 0.0001\n",
            "[2022-10-03 22:00:36] 1/4, train_loss: 0.5898\n",
            "[2022-10-03 22:00:37] 2/4, train_loss: 0.5567\n",
            "[2022-10-03 22:00:37] 3/4, train_loss: 0.5275\n",
            "[2022-10-03 22:00:38] 4/4, train_loss: 0.4982\n",
            "epoch 3 average loss: 0.5430, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 4/40\n",
            "learning rate is set to 0.0001\n",
            "[2022-10-03 22:00:39] 1/4, train_loss: 0.4711\n",
            "[2022-10-03 22:00:40] 2/4, train_loss: 0.4441\n",
            "[2022-10-03 22:00:40] 3/4, train_loss: 0.4285\n",
            "[2022-10-03 22:00:41] 4/4, train_loss: 0.3952\n",
            "epoch 4 average loss: 0.4347, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 5/40\n",
            "learning rate is set to 0.0001\n",
            "[2022-10-03 22:00:42] 1/4, train_loss: 0.3847\n",
            "[2022-10-03 22:00:42] 2/4, train_loss: 0.3615\n",
            "[2022-10-03 22:00:43] 3/4, train_loss: 0.3483\n",
            "[2022-10-03 22:00:43] 4/4, train_loss: 0.3206\n",
            "epoch 5 average loss: 0.3538, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 6/40\n",
            "learning rate is set to 0.0001\n",
            "[2022-10-03 22:00:44] 1/4, train_loss: 0.3059\n",
            "[2022-10-03 22:00:45] 2/4, train_loss: 0.2936\n",
            "[2022-10-03 22:00:46] 3/4, train_loss: 0.2785\n",
            "[2022-10-03 22:00:46] 4/4, train_loss: 0.2677\n",
            "epoch 6 average loss: 0.2865, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 7/40\n",
            "learning rate is set to 0.0001\n",
            "[2022-10-03 22:00:47] 1/4, train_loss: 0.2634\n",
            "[2022-10-03 22:00:48] 2/4, train_loss: 0.2432\n",
            "[2022-10-03 22:00:48] 3/4, train_loss: 0.2407\n",
            "[2022-10-03 22:00:49] 4/4, train_loss: 0.2383\n",
            "epoch 7 average loss: 0.2464, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 8/40\n",
            "learning rate is set to 0.0001\n",
            "[2022-10-03 22:00:50] 1/4, train_loss: 0.2233\n",
            "[2022-10-03 22:00:50] 2/4, train_loss: 0.2165\n",
            "[2022-10-03 22:00:51] 3/4, train_loss: 0.2142\n",
            "[2022-10-03 22:00:51] 4/4, train_loss: 0.1912\n",
            "epoch 8 average loss: 0.2113, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 9/40\n",
            "learning rate is set to 5e-05\n",
            "[2022-10-03 22:00:53] 1/4, train_loss: 0.1791\n",
            "[2022-10-03 22:00:53] 2/4, train_loss: 0.1826\n",
            "[2022-10-03 22:00:53] 3/4, train_loss: 0.1717\n",
            "[2022-10-03 22:00:54] 4/4, train_loss: 0.1718\n",
            "epoch 9 average loss: 0.1763, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 10/40\n",
            "learning rate is set to 5e-05\n",
            "[2022-10-03 22:00:55] 1/4, train_loss: 0.1674\n",
            "[2022-10-03 22:00:56] 2/4, train_loss: 0.1537\n",
            "[2022-10-03 22:00:56] 3/4, train_loss: 0.1567\n",
            "[2022-10-03 22:00:57] 4/4, train_loss: 0.1534\n",
            "epoch 10 average loss: 0.1578, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 11/40\n",
            "learning rate is set to 5e-05\n",
            "[2022-10-03 22:00:58] 1/4, train_loss: 0.1475\n",
            "[2022-10-03 22:00:58] 2/4, train_loss: 0.1489\n",
            "[2022-10-03 22:00:59] 3/4, train_loss: 0.1370\n",
            "[2022-10-03 22:01:00] 4/4, train_loss: 0.1408\n",
            "epoch 11 average loss: 0.1436, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 12/40\n",
            "learning rate is set to 5e-05\n",
            "[2022-10-03 22:01:01] 1/4, train_loss: 0.1327\n",
            "[2022-10-03 22:01:01] 2/4, train_loss: 0.1424\n",
            "[2022-10-03 22:01:02] 3/4, train_loss: 0.1263\n",
            "[2022-10-03 22:01:02] 4/4, train_loss: 0.1234\n",
            "epoch 12 average loss: 0.1312, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 13/40\n",
            "learning rate is set to 5e-05\n",
            "[2022-10-03 22:01:03] 1/4, train_loss: 0.1205\n",
            "[2022-10-03 22:01:04] 2/4, train_loss: 0.1180\n",
            "[2022-10-03 22:01:04] 3/4, train_loss: 0.1318\n",
            "[2022-10-03 22:01:05] 4/4, train_loss: 0.1197\n",
            "epoch 13 average loss: 0.1225, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 14/40\n",
            "learning rate is set to 5e-05\n",
            "[2022-10-03 22:01:06] 1/4, train_loss: 0.1136\n",
            "[2022-10-03 22:01:06] 2/4, train_loss: 0.1161\n",
            "[2022-10-03 22:01:07] 3/4, train_loss: 0.1085\n",
            "[2022-10-03 22:01:08] 4/4, train_loss: 0.1106\n",
            "epoch 14 average loss: 0.1122, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 15/40\n",
            "learning rate is set to 5e-05\n",
            "[2022-10-03 22:01:09] 1/4, train_loss: 0.1099\n",
            "[2022-10-03 22:01:10] 2/4, train_loss: 0.1059\n",
            "[2022-10-03 22:01:11] 3/4, train_loss: 0.1050\n",
            "[2022-10-03 22:01:11] 4/4, train_loss: 0.1004\n",
            "epoch 15 average loss: 0.1053, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 16/40\n",
            "learning rate is set to 5e-05\n",
            "[2022-10-03 22:01:12] 1/4, train_loss: 0.0998\n",
            "[2022-10-03 22:01:13] 2/4, train_loss: 0.0965\n",
            "[2022-10-03 22:01:14] 3/4, train_loss: 0.0953\n",
            "[2022-10-03 22:01:14] 4/4, train_loss: 0.0946\n",
            "epoch 16 average loss: 0.0966, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 17/40\n",
            "learning rate is set to 2.5e-05\n",
            "[2022-10-03 22:01:15] 1/4, train_loss: 0.0953\n",
            "[2022-10-03 22:01:16] 2/4, train_loss: 0.0912\n",
            "[2022-10-03 22:01:16] 3/4, train_loss: 0.1058\n",
            "[2022-10-03 22:01:17] 4/4, train_loss: 0.1252\n",
            "epoch 17 average loss: 0.1044, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 18/40\n",
            "learning rate is set to 2.5e-05\n",
            "[2022-10-03 22:01:18] 1/4, train_loss: 0.0915\n",
            "[2022-10-03 22:01:18] 2/4, train_loss: 0.0895\n",
            "[2022-10-03 22:01:19] 3/4, train_loss: 0.0902\n",
            "[2022-10-03 22:01:20] 4/4, train_loss: 0.0875\n",
            "epoch 18 average loss: 0.0897, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 19/40\n",
            "learning rate is set to 2.5e-05\n",
            "[2022-10-03 22:01:21] 1/4, train_loss: 0.0866\n",
            "[2022-10-03 22:01:21] 2/4, train_loss: 0.0882\n",
            "[2022-10-03 22:01:22] 3/4, train_loss: 0.0854\n",
            "[2022-10-03 22:01:22] 4/4, train_loss: 0.0845\n",
            "epoch 19 average loss: 0.0862, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 20/40\n",
            "learning rate is set to 2.5e-05\n",
            "[2022-10-03 22:01:23] 1/4, train_loss: 0.0856\n",
            "[2022-10-03 22:01:24] 2/4, train_loss: 0.0832\n",
            "[2022-10-03 22:01:24] 3/4, train_loss: 0.0826\n",
            "[2022-10-03 22:01:25] 4/4, train_loss: 0.1033\n",
            "epoch 20 average loss: 0.0887, best mean dice: -1.0000 at epoch -1\n",
            "1 / 4 tensor([[0.9941]], device='cuda:0')\n",
            "2 / 4 tensor([[0.9941]], device='cuda:0')\n",
            "3 / 4 tensor([[0.9941]], device='cuda:0')\n",
            "4 / 4 tensor([[0.9941]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.9940875172615051\n",
            "avg_metric 0.9940875172615051\n",
            "saved new best metric model\n",
            "current epoch: 20 current mean dice: 0.9941 best mean dice: 0.9941 at epoch 20\n",
            "----------\n",
            "epoch 21/40\n",
            "learning rate is set to 2.5e-05\n",
            "[2022-10-03 22:01:28] 1/4, train_loss: 0.0840\n",
            "[2022-10-03 22:01:28] 2/4, train_loss: 0.1529\n",
            "[2022-10-03 22:01:29] 3/4, train_loss: 0.0831\n",
            "[2022-10-03 22:01:29] 4/4, train_loss: 0.0890\n",
            "epoch 21 average loss: 0.1022, best mean dice: 0.9941 at epoch 20\n",
            "----------\n",
            "epoch 22/40\n",
            "learning rate is set to 2.5e-05\n",
            "[2022-10-03 22:01:31] 1/4, train_loss: 0.0921\n",
            "[2022-10-03 22:01:31] 2/4, train_loss: 0.0814\n",
            "[2022-10-03 22:01:32] 3/4, train_loss: 0.0789\n",
            "[2022-10-03 22:01:32] 4/4, train_loss: 0.0963\n",
            "epoch 22 average loss: 0.0872, best mean dice: 0.9941 at epoch 20\n",
            "----------\n",
            "epoch 23/40\n",
            "learning rate is set to 2.5e-05\n",
            "[2022-10-03 22:01:33] 1/4, train_loss: 0.0782\n",
            "[2022-10-03 22:01:34] 2/4, train_loss: 0.0809\n",
            "[2022-10-03 22:01:34] 3/4, train_loss: 0.0770\n",
            "[2022-10-03 22:01:35] 4/4, train_loss: 0.0920\n",
            "epoch 23 average loss: 0.0820, best mean dice: 0.9941 at epoch 20\n",
            "----------\n",
            "epoch 24/40\n",
            "learning rate is set to 2.5e-05\n",
            "[2022-10-03 22:01:36] 1/4, train_loss: 0.0880\n",
            "[2022-10-03 22:01:36] 2/4, train_loss: 0.0761\n",
            "[2022-10-03 22:01:37] 3/4, train_loss: 0.0767\n",
            "[2022-10-03 22:01:38] 4/4, train_loss: 0.0875\n",
            "epoch 24 average loss: 0.0821, best mean dice: 0.9941 at epoch 20\n",
            "----------\n",
            "epoch 25/40\n",
            "learning rate is set to 1.25e-05\n",
            "[2022-10-03 22:01:40] 1/4, train_loss: 0.0957\n",
            "[2022-10-03 22:01:40] 2/4, train_loss: 0.0776\n",
            "[2022-10-03 22:01:41] 3/4, train_loss: 0.0880\n",
            "[2022-10-03 22:01:41] 4/4, train_loss: 0.0756\n",
            "epoch 25 average loss: 0.0842, best mean dice: 0.9941 at epoch 20\n",
            "----------\n",
            "epoch 26/40\n",
            "learning rate is set to 1.25e-05\n",
            "[2022-10-03 22:01:42] 1/4, train_loss: 0.0731\n",
            "[2022-10-03 22:01:43] 2/4, train_loss: 0.0947\n",
            "[2022-10-03 22:01:43] 3/4, train_loss: 0.0772\n",
            "[2022-10-03 22:01:44] 4/4, train_loss: 0.0890\n",
            "epoch 26 average loss: 0.0835, best mean dice: 0.9941 at epoch 20\n",
            "----------\n",
            "epoch 27/40\n",
            "learning rate is set to 1.25e-05\n",
            "[2022-10-03 22:01:45] 1/4, train_loss: 0.0799\n",
            "[2022-10-03 22:01:45] 2/4, train_loss: 0.0732\n",
            "[2022-10-03 22:01:46] 3/4, train_loss: 0.0732\n",
            "[2022-10-03 22:01:46] 4/4, train_loss: 0.0717\n",
            "epoch 27 average loss: 0.0745, best mean dice: 0.9941 at epoch 20\n",
            "----------\n",
            "epoch 28/40\n",
            "learning rate is set to 1.25e-05\n",
            "[2022-10-03 22:01:48] 1/4, train_loss: 0.0856\n",
            "[2022-10-03 22:01:48] 2/4, train_loss: 0.1253\n",
            "[2022-10-03 22:01:49] 3/4, train_loss: 0.0723\n",
            "[2022-10-03 22:01:49] 4/4, train_loss: 0.0941\n",
            "epoch 28 average loss: 0.0943, best mean dice: 0.9941 at epoch 20\n",
            "----------\n",
            "epoch 29/40\n",
            "learning rate is set to 1.25e-05\n",
            "[2022-10-03 22:01:50] 1/4, train_loss: 0.0705\n",
            "[2022-10-03 22:01:51] 2/4, train_loss: 0.0825\n",
            "[2022-10-03 22:01:51] 3/4, train_loss: 0.0702\n",
            "[2022-10-03 22:01:52] 4/4, train_loss: 0.1001\n",
            "epoch 29 average loss: 0.0809, best mean dice: 0.9941 at epoch 20\n",
            "----------\n",
            "epoch 30/40\n",
            "learning rate is set to 1.25e-05\n",
            "[2022-10-03 22:01:53] 1/4, train_loss: 0.0718\n",
            "[2022-10-03 22:01:54] 2/4, train_loss: 0.0761\n",
            "[2022-10-03 22:01:54] 3/4, train_loss: 0.0695\n",
            "[2022-10-03 22:01:55] 4/4, train_loss: 0.0694\n",
            "epoch 30 average loss: 0.0717, best mean dice: 0.9941 at epoch 20\n",
            "----------\n",
            "epoch 31/40\n",
            "learning rate is set to 1.25e-05\n",
            "[2022-10-03 22:01:56] 1/4, train_loss: 0.0706\n",
            "[2022-10-03 22:01:56] 2/4, train_loss: 0.0910\n",
            "[2022-10-03 22:01:57] 3/4, train_loss: 0.0687\n",
            "[2022-10-03 22:01:57] 4/4, train_loss: 0.0751\n",
            "epoch 31 average loss: 0.0764, best mean dice: 0.9941 at epoch 20\n",
            "----------\n",
            "epoch 32/40\n",
            "learning rate is set to 1.25e-05\n",
            "[2022-10-03 22:01:59] 1/4, train_loss: 0.0726\n",
            "[2022-10-03 22:01:59] 2/4, train_loss: 0.0813\n",
            "[2022-10-03 22:02:00] 3/4, train_loss: 0.0684\n",
            "[2022-10-03 22:02:00] 4/4, train_loss: 0.0834\n",
            "epoch 32 average loss: 0.0764, best mean dice: 0.9941 at epoch 20\n",
            "----------\n",
            "epoch 33/40\n",
            "learning rate is set to 6.25e-06\n",
            "[2022-10-03 22:02:01] 1/4, train_loss: 0.0993\n",
            "[2022-10-03 22:02:02] 2/4, train_loss: 0.0688\n",
            "[2022-10-03 22:02:03] 3/4, train_loss: 0.0699\n",
            "[2022-10-03 22:02:03] 4/4, train_loss: 0.0840\n",
            "epoch 33 average loss: 0.0805, best mean dice: 0.9941 at epoch 20\n",
            "----------\n",
            "epoch 34/40\n",
            "learning rate is set to 6.25e-06\n",
            "[2022-10-03 22:02:04] 1/4, train_loss: 0.0796\n",
            "[2022-10-03 22:02:05] 2/4, train_loss: 0.0688\n",
            "[2022-10-03 22:02:05] 3/4, train_loss: 0.0908\n",
            "[2022-10-03 22:02:06] 4/4, train_loss: 0.0688\n",
            "epoch 34 average loss: 0.0770, best mean dice: 0.9941 at epoch 20\n",
            "----------\n",
            "epoch 35/40\n",
            "learning rate is set to 6.25e-06\n",
            "[2022-10-03 22:02:07] 1/4, train_loss: 0.0698\n",
            "[2022-10-03 22:02:07] 2/4, train_loss: 0.0685\n",
            "[2022-10-03 22:02:08] 3/4, train_loss: 0.0666\n",
            "[2022-10-03 22:02:08] 4/4, train_loss: 0.0666\n",
            "epoch 35 average loss: 0.0679, best mean dice: 0.9941 at epoch 20\n",
            "----------\n",
            "epoch 36/40\n",
            "learning rate is set to 6.25e-06\n",
            "[2022-10-03 22:02:09] 1/4, train_loss: 0.0706\n",
            "[2022-10-03 22:02:10] 2/4, train_loss: 0.0769\n",
            "[2022-10-03 22:02:10] 3/4, train_loss: 0.0679\n",
            "[2022-10-03 22:02:11] 4/4, train_loss: 0.0693\n",
            "epoch 36 average loss: 0.0712, best mean dice: 0.9941 at epoch 20\n",
            "----------\n",
            "epoch 37/40\n",
            "learning rate is set to 6.25e-06\n",
            "[2022-10-03 22:02:12] 1/4, train_loss: 0.0660\n",
            "[2022-10-03 22:02:13] 2/4, train_loss: 0.0713\n",
            "[2022-10-03 22:02:13] 3/4, train_loss: 0.0725\n",
            "[2022-10-03 22:02:14] 4/4, train_loss: 0.0793\n",
            "epoch 37 average loss: 0.0723, best mean dice: 0.9941 at epoch 20\n",
            "----------\n",
            "epoch 38/40\n",
            "learning rate is set to 6.25e-06\n",
            "[2022-10-03 22:02:15] 1/4, train_loss: 0.0793\n",
            "[2022-10-03 22:02:15] 2/4, train_loss: 0.0839\n",
            "[2022-10-03 22:02:16] 3/4, train_loss: 0.0659\n",
            "[2022-10-03 22:02:17] 4/4, train_loss: 0.0687\n",
            "epoch 38 average loss: 0.0745, best mean dice: 0.9941 at epoch 20\n",
            "----------\n",
            "epoch 39/40\n",
            "learning rate is set to 6.25e-06\n",
            "[2022-10-03 22:02:18] 1/4, train_loss: 0.0692\n",
            "[2022-10-03 22:02:18] 2/4, train_loss: 0.0668\n",
            "[2022-10-03 22:02:19] 3/4, train_loss: 0.0883\n",
            "[2022-10-03 22:02:19] 4/4, train_loss: 0.0674\n",
            "epoch 39 average loss: 0.0729, best mean dice: 0.9941 at epoch 20\n",
            "----------\n",
            "epoch 40/40\n",
            "learning rate is set to 6.25e-06\n",
            "[2022-10-03 22:02:20] 1/4, train_loss: 0.0661\n",
            "[2022-10-03 22:02:21] 2/4, train_loss: 0.0665\n",
            "[2022-10-03 22:02:21] 3/4, train_loss: 0.0647\n",
            "[2022-10-03 22:02:22] 4/4, train_loss: 0.0647\n",
            "epoch 40 average loss: 0.0655, best mean dice: 0.9941 at epoch 20\n",
            "1 / 4 tensor([[0.9970]], device='cuda:0')\n",
            "2 / 4 tensor([[0.9970]], device='cuda:0')\n",
            "3 / 4 tensor([[0.9970]], device='cuda:0')\n",
            "4 / 4 tensor([[0.9970]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.9969981908798218\n",
            "avg_metric 0.9969981908798218\n",
            "saved new best metric model\n",
            "current epoch: 40 current mean dice: 0.9970 best mean dice: 0.9970 at epoch 40\n",
            "train completed, best_metric: 0.9970 at epoch: 40\n",
            "0.9969981908798218\n",
            "\", stderr=b'')\n",
            "2022-10-03 22:02:25,878 - INFO - Launching: python /content/helloworld_work_dir/dints_0/scripts/search.py run --config_file='/content/helloworld_work_dir/dints_0/configs/network_search.yaml','/content/helloworld_work_dir/dints_0/configs/transforms_train.yaml','/content/helloworld_work_dir/dints_0/configs/hyper_parameters_search.yaml','/content/helloworld_work_dir/dints_0/configs/transforms_infer.yaml','/content/helloworld_work_dir/dints_0/configs/network.yaml','/content/helloworld_work_dir/dints_0/configs/hyper_parameters.yaml','/content/helloworld_work_dir/dints_0/configs/transforms_validate.yaml' --searching#num_iterations=160 --searching#num_iterations_per_validation=80 --searching#num_images_per_batch=2 --searching#num_epochs=40 --searching#num_warmup_iterations=80\n",
            "2022-10-03 22:11:38,285 - INFO - CompletedProcess(args=['python', '/content/helloworld_work_dir/dints_0/scripts/search.py', 'run', \"--config_file='/content/helloworld_work_dir/dints_0/configs/network_search.yaml','/content/helloworld_work_dir/dints_0/configs/transforms_train.yaml','/content/helloworld_work_dir/dints_0/configs/hyper_parameters_search.yaml','/content/helloworld_work_dir/dints_0/configs/transforms_infer.yaml','/content/helloworld_work_dir/dints_0/configs/network.yaml','/content/helloworld_work_dir/dints_0/configs/hyper_parameters.yaml','/content/helloworld_work_dir/dints_0/configs/transforms_validate.yaml'\", '--searching#num_iterations=160', '--searching#num_iterations_per_validation=80', '--searching#num_images_per_batch=2', '--searching#num_epochs=40', '--searching#num_warmup_iterations=80'], returncode=0, stdout=b\"[info] number of GPUs: 1\n",
            "[info] world_size: 1\n",
            "train_files_w: 4\n",
            "train_files_a: 4\n",
            "val_files: 4\n",
            "num_epochs 80\n",
            "num_epochs_warmup 40\n",
            "num_epochs_per_validation 40\n",
            "[info] amp enabled\n",
            "----------\n",
            "epoch 1/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:02:41] 1/2, train_loss: 0.8136\n",
            "[2022-10-03 22:02:43] 2/2, train_loss: 0.8512\n",
            "epoch 1 average loss: 0.8324, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 2/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:02:45] 1/2, train_loss: 0.8054\n",
            "[2022-10-03 22:02:47] 2/2, train_loss: 0.7833\n",
            "epoch 2 average loss: 0.7944, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 3/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:02:49] 1/2, train_loss: 0.7874\n",
            "[2022-10-03 22:02:51] 2/2, train_loss: 0.7476\n",
            "epoch 3 average loss: 0.7675, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 4/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:02:53] 1/2, train_loss: 0.7811\n",
            "[2022-10-03 22:02:55] 2/2, train_loss: 0.7988\n",
            "epoch 4 average loss: 0.7900, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 5/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:02:57] 1/2, train_loss: 0.8172\n",
            "[2022-10-03 22:02:59] 2/2, train_loss: 0.7729\n",
            "epoch 5 average loss: 0.7950, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 6/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:03:01] 1/2, train_loss: 0.7398\n",
            "[2022-10-03 22:03:03] 2/2, train_loss: 0.7724\n",
            "epoch 6 average loss: 0.7561, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 7/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:03:05] 1/2, train_loss: 0.7788\n",
            "[2022-10-03 22:03:07] 2/2, train_loss: 0.7578\n",
            "epoch 7 average loss: 0.7683, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 8/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:03:09] 1/2, train_loss: 0.8055\n",
            "[2022-10-03 22:03:11] 2/2, train_loss: 0.7386\n",
            "epoch 8 average loss: 0.7721, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 9/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:03:13] 1/2, train_loss: 0.7245\n",
            "[2022-10-03 22:03:15] 2/2, train_loss: 0.7218\n",
            "epoch 9 average loss: 0.7231, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 10/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:03:17] 1/2, train_loss: 0.7510\n",
            "[2022-10-03 22:03:19] 2/2, train_loss: 0.6855\n",
            "epoch 10 average loss: 0.7183, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 11/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:03:21] 1/2, train_loss: 0.6944\n",
            "[2022-10-03 22:03:23] 2/2, train_loss: 0.7262\n",
            "epoch 11 average loss: 0.7103, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 12/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:03:26] 1/2, train_loss: 0.7596\n",
            "[2022-10-03 22:03:28] 2/2, train_loss: 0.6896\n",
            "epoch 12 average loss: 0.7246, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 13/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:03:30] 1/2, train_loss: 0.6903\n",
            "[2022-10-03 22:03:32] 2/2, train_loss: 0.6784\n",
            "epoch 13 average loss: 0.6844, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 14/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:03:34] 1/2, train_loss: 0.6712\n",
            "[2022-10-03 22:03:36] 2/2, train_loss: 0.7325\n",
            "epoch 14 average loss: 0.7018, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 15/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:03:40] 1/2, train_loss: 0.6851\n",
            "[2022-10-03 22:03:41] 2/2, train_loss: 0.6579\n",
            "epoch 15 average loss: 0.6715, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 16/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:03:44] 1/2, train_loss: 0.6434\n",
            "[2022-10-03 22:03:45] 2/2, train_loss: 0.6482\n",
            "epoch 16 average loss: 0.6458, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 17/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:03:48] 1/2, train_loss: 0.6572\n",
            "[2022-10-03 22:03:49] 2/2, train_loss: 0.6638\n",
            "epoch 17 average loss: 0.6605, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 18/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:03:52] 1/2, train_loss: 0.6354\n",
            "[2022-10-03 22:03:53] 2/2, train_loss: 0.6147\n",
            "epoch 18 average loss: 0.6251, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 19/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:03:56] 1/2, train_loss: 0.6453\n",
            "[2022-10-03 22:03:57] 2/2, train_loss: 0.6342\n",
            "epoch 19 average loss: 0.6397, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 20/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:04:00] 1/2, train_loss: 0.6341\n",
            "[2022-10-03 22:04:02] 2/2, train_loss: 0.6413\n",
            "epoch 20 average loss: 0.6377, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 21/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:04:04] 1/2, train_loss: 0.6090\n",
            "[2022-10-03 22:04:06] 2/2, train_loss: 0.6087\n",
            "epoch 21 average loss: 0.6089, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 22/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:04:09] 1/2, train_loss: 0.5842\n",
            "[2022-10-03 22:04:10] 2/2, train_loss: 0.6042\n",
            "epoch 22 average loss: 0.5942, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 23/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:04:13] 1/2, train_loss: 0.5811\n",
            "[2022-10-03 22:04:14] 2/2, train_loss: 0.5962\n",
            "epoch 23 average loss: 0.5887, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 24/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:04:17] 1/2, train_loss: 0.5619\n",
            "[2022-10-03 22:04:18] 2/2, train_loss: 0.5923\n",
            "epoch 24 average loss: 0.5771, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 25/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:04:21] 1/2, train_loss: 0.5995\n",
            "[2022-10-03 22:04:22] 2/2, train_loss: 0.5582\n",
            "epoch 25 average loss: 0.5788, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 26/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:04:25] 1/2, train_loss: 0.5529\n",
            "[2022-10-03 22:04:26] 2/2, train_loss: 0.5712\n",
            "epoch 26 average loss: 0.5620, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 27/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:04:29] 1/2, train_loss: 0.5991\n",
            "[2022-10-03 22:04:30] 2/2, train_loss: 0.5628\n",
            "epoch 27 average loss: 0.5809, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 28/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:04:33] 1/2, train_loss: 0.5501\n",
            "[2022-10-03 22:04:34] 2/2, train_loss: 0.5431\n",
            "epoch 28 average loss: 0.5466, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 29/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:04:37] 1/2, train_loss: 0.5592\n",
            "[2022-10-03 22:04:38] 2/2, train_loss: 0.5349\n",
            "epoch 29 average loss: 0.5471, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 30/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:04:41] 1/2, train_loss: 0.5511\n",
            "[2022-10-03 22:04:42] 2/2, train_loss: 0.5101\n",
            "epoch 30 average loss: 0.5306, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 31/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:04:45] 1/2, train_loss: 0.5294\n",
            "[2022-10-03 22:04:46] 2/2, train_loss: 0.5278\n",
            "epoch 31 average loss: 0.5286, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 32/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:04:49] 1/2, train_loss: 0.5125\n",
            "[2022-10-03 22:04:50] 2/2, train_loss: 0.5551\n",
            "epoch 32 average loss: 0.5338, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 33/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:04:53] 1/2, train_loss: 0.5206\n",
            "[2022-10-03 22:04:55] 2/2, train_loss: 0.5174\n",
            "epoch 33 average loss: 0.5190, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 34/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:04:57] 1/2, train_loss: 0.5129\n",
            "[2022-10-03 22:04:59] 2/2, train_loss: 0.5058\n",
            "epoch 34 average loss: 0.5093, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 35/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:05:01] 1/2, train_loss: 0.5310\n",
            "[2022-10-03 22:05:03] 2/2, train_loss: 0.5202\n",
            "epoch 35 average loss: 0.5256, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 36/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:05:05] 1/2, train_loss: 0.4862\n",
            "[2022-10-03 22:05:07] 2/2, train_loss: 0.4891\n",
            "epoch 36 average loss: 0.4876, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 37/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:05:09] 1/2, train_loss: 0.5240\n",
            "[2022-10-03 22:05:11] 2/2, train_loss: 0.5233\n",
            "epoch 37 average loss: 0.5237, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 38/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:05:13] 1/2, train_loss: 0.5131\n",
            "[2022-10-03 22:05:15] 2/2, train_loss: 0.4729\n",
            "epoch 38 average loss: 0.4930, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 39/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:05:17] 1/2, train_loss: 0.4554\n",
            "[2022-10-03 22:05:19] 2/2, train_loss: 0.4711\n",
            "epoch 39 average loss: 0.4633, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 40/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:05:22] 1/2, train_loss: 0.4499\n",
            "[2022-10-03 22:05:24] 2/2, train_loss: 0.4548\n",
            "epoch 40 average loss: 0.4524, best mean dice: -1.0000 at epoch -1\n",
            "1 / 4 tensor([[0.5842]], device='cuda:0')\n",
            "2 / 4 tensor([[0.5842]], device='cuda:0')\n",
            "3 / 4 tensor([[0.5842]], device='cuda:0')\n",
            "4 / 4 tensor([[0.5842]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.5842020511627197\n",
            "avg_metric 0.5842020511627197\n",
            "saved new best metric model\n",
            "current epoch: 40 current mean dice: 0.5842 best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 41/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:05:41] 1/2, train_loss: 0.4611\n",
            "[2022-10-03 22:05:44] 1/2, train_loss_arch: 0.4379\n",
            "[2022-10-03 22:05:45] 2/2, train_loss: 0.4938\n",
            "[2022-10-03 22:05:47] 2/2, train_loss_arch: 0.4408\n",
            "epoch 41 average loss: 0.4774, best mean dice: 0.5842 at epoch 40\n",
            "epoch 41 average arch loss: 0.4393, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 42/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:05:50] 1/2, train_loss: 0.4208\n",
            "[2022-10-03 22:05:52] 1/2, train_loss_arch: 0.4375\n",
            "[2022-10-03 22:05:54] 2/2, train_loss: 0.4312\n",
            "[2022-10-03 22:05:55] 2/2, train_loss_arch: 0.4717\n",
            "epoch 42 average loss: 0.4260, best mean dice: 0.5842 at epoch 40\n",
            "epoch 42 average arch loss: 0.4546, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 43/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:05:58] 1/2, train_loss: 0.4589\n",
            "[2022-10-03 22:06:01] 1/2, train_loss_arch: 0.4673\n",
            "[2022-10-03 22:06:02] 2/2, train_loss: 0.4249\n",
            "[2022-10-03 22:06:04] 2/2, train_loss_arch: 0.4910\n",
            "epoch 43 average loss: 0.4419, best mean dice: 0.5842 at epoch 40\n",
            "epoch 43 average arch loss: 0.4791, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 44/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:06:08] 1/2, train_loss: 0.4463\n",
            "[2022-10-03 22:06:11] 1/2, train_loss_arch: 0.4661\n",
            "[2022-10-03 22:06:12] 2/2, train_loss: 0.4431\n",
            "[2022-10-03 22:06:14] 2/2, train_loss_arch: 0.4783\n",
            "epoch 44 average loss: 0.4447, best mean dice: 0.5842 at epoch 40\n",
            "epoch 44 average arch loss: 0.4722, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 45/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:06:16] 1/2, train_loss: 0.4182\n",
            "[2022-10-03 22:06:19] 1/2, train_loss_arch: 0.4793\n",
            "[2022-10-03 22:06:21] 2/2, train_loss: 0.4217\n",
            "[2022-10-03 22:06:22] 2/2, train_loss_arch: 0.4740\n",
            "epoch 45 average loss: 0.4199, best mean dice: 0.5842 at epoch 40\n",
            "epoch 45 average arch loss: 0.4766, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 46/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:06:25] 1/2, train_loss: 0.4019\n",
            "[2022-10-03 22:06:27] 1/2, train_loss_arch: 0.5257\n",
            "[2022-10-03 22:06:29] 2/2, train_loss: 0.3999\n",
            "[2022-10-03 22:06:30] 2/2, train_loss_arch: 0.4830\n",
            "epoch 46 average loss: 0.4009, best mean dice: 0.5842 at epoch 40\n",
            "epoch 46 average arch loss: 0.5044, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 47/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:06:33] 1/2, train_loss: 0.4066\n",
            "[2022-10-03 22:06:36] 1/2, train_loss_arch: 0.5119\n",
            "[2022-10-03 22:06:37] 2/2, train_loss: 0.4092\n",
            "[2022-10-03 22:06:39] 2/2, train_loss_arch: 0.5059\n",
            "epoch 47 average loss: 0.4079, best mean dice: 0.5842 at epoch 40\n",
            "epoch 47 average arch loss: 0.5089, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 48/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:06:42] 1/2, train_loss: 0.4241\n",
            "[2022-10-03 22:06:45] 1/2, train_loss_arch: 0.5503\n",
            "[2022-10-03 22:06:46] 2/2, train_loss: 0.3933\n",
            "[2022-10-03 22:06:47] 2/2, train_loss_arch: 0.5361\n",
            "epoch 48 average loss: 0.4087, best mean dice: 0.5842 at epoch 40\n",
            "epoch 48 average arch loss: 0.5432, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 49/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:06:50] 1/2, train_loss: 0.3886\n",
            "[2022-10-03 22:06:53] 1/2, train_loss_arch: 0.5038\n",
            "[2022-10-03 22:06:55] 2/2, train_loss: 0.3861\n",
            "[2022-10-03 22:06:56] 2/2, train_loss_arch: 0.5516\n",
            "epoch 49 average loss: 0.3874, best mean dice: 0.5842 at epoch 40\n",
            "epoch 49 average arch loss: 0.5277, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 50/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:06:59] 1/2, train_loss: 0.3807\n",
            "[2022-10-03 22:07:01] 1/2, train_loss_arch: 0.5413\n",
            "[2022-10-03 22:07:03] 2/2, train_loss: 0.4596\n",
            "[2022-10-03 22:07:04] 2/2, train_loss_arch: 0.5204\n",
            "epoch 50 average loss: 0.4202, best mean dice: 0.5842 at epoch 40\n",
            "epoch 50 average arch loss: 0.5309, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 51/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:07:07] 1/2, train_loss: 0.3811\n",
            "[2022-10-03 22:07:10] 1/2, train_loss_arch: 0.5720\n",
            "[2022-10-03 22:07:11] 2/2, train_loss: 0.3605\n",
            "[2022-10-03 22:07:13] 2/2, train_loss_arch: 0.5972\n",
            "epoch 51 average loss: 0.3708, best mean dice: 0.5842 at epoch 40\n",
            "epoch 51 average arch loss: 0.5846, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 52/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:07:15] 1/2, train_loss: 0.3446\n",
            "[2022-10-03 22:07:18] 1/2, train_loss_arch: 0.5614\n",
            "[2022-10-03 22:07:20] 2/2, train_loss: 0.4007\n",
            "[2022-10-03 22:07:21] 2/2, train_loss_arch: 0.5728\n",
            "epoch 52 average loss: 0.3726, best mean dice: 0.5842 at epoch 40\n",
            "epoch 52 average arch loss: 0.5671, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 53/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:07:24] 1/2, train_loss: 0.3650\n",
            "[2022-10-03 22:07:27] 1/2, train_loss_arch: 0.6016\n",
            "[2022-10-03 22:07:28] 2/2, train_loss: 0.3486\n",
            "[2022-10-03 22:07:30] 2/2, train_loss_arch: 0.5516\n",
            "epoch 53 average loss: 0.3568, best mean dice: 0.5842 at epoch 40\n",
            "epoch 53 average arch loss: 0.5766, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 54/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:07:32] 1/2, train_loss: 0.3734\n",
            "[2022-10-03 22:07:35] 1/2, train_loss_arch: 0.5414\n",
            "[2022-10-03 22:07:37] 2/2, train_loss: 0.3356\n",
            "[2022-10-03 22:07:38] 2/2, train_loss_arch: 0.5613\n",
            "epoch 54 average loss: 0.3545, best mean dice: 0.5842 at epoch 40\n",
            "epoch 54 average arch loss: 0.5514, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 55/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:07:41] 1/2, train_loss: 0.3546\n",
            "[2022-10-03 22:07:44] 1/2, train_loss_arch: 0.5510\n",
            "[2022-10-03 22:07:45] 2/2, train_loss: 0.4058\n",
            "[2022-10-03 22:07:46] 2/2, train_loss_arch: 0.6196\n",
            "epoch 55 average loss: 0.3802, best mean dice: 0.5842 at epoch 40\n",
            "epoch 55 average arch loss: 0.5853, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 56/80\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:07:49] 1/2, train_loss: 0.3685\n",
            "[2022-10-03 22:07:52] 1/2, train_loss_arch: 0.6143\n",
            "[2022-10-03 22:07:54] 2/2, train_loss: 0.3872\n",
            "[2022-10-03 22:07:55] 2/2, train_loss_arch: 0.5887\n",
            "epoch 56 average loss: 0.3779, best mean dice: 0.5842 at epoch 40\n",
            "epoch 56 average arch loss: 0.6015, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 57/80\n",
            "learning rate is set to 0.0125\n",
            "[2022-10-03 22:07:58] 1/2, train_loss: 0.3177\n",
            "[2022-10-03 22:08:01] 1/2, train_loss_arch: 0.5847\n",
            "[2022-10-03 22:08:02] 2/2, train_loss: 0.3210\n",
            "[2022-10-03 22:08:04] 2/2, train_loss_arch: 0.6026\n",
            "epoch 57 average loss: 0.3194, best mean dice: 0.5842 at epoch 40\n",
            "epoch 57 average arch loss: 0.5936, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 58/80\n",
            "learning rate is set to 0.0125\n",
            "[2022-10-03 22:08:06] 1/2, train_loss: 0.3704\n",
            "[2022-10-03 22:08:09] 1/2, train_loss_arch: 0.6119\n",
            "[2022-10-03 22:08:11] 2/2, train_loss: 0.3103\n",
            "[2022-10-03 22:08:12] 2/2, train_loss_arch: 0.6204\n",
            "epoch 58 average loss: 0.3403, best mean dice: 0.5842 at epoch 40\n",
            "epoch 58 average arch loss: 0.6161, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 59/80\n",
            "learning rate is set to 0.0125\n",
            "[2022-10-03 22:08:15] 1/2, train_loss: 0.3816\n",
            "[2022-10-03 22:08:18] 1/2, train_loss_arch: 0.6574\n",
            "[2022-10-03 22:08:19] 2/2, train_loss: 0.3067\n",
            "[2022-10-03 22:08:20] 2/2, train_loss_arch: 0.5973\n",
            "epoch 59 average loss: 0.3442, best mean dice: 0.5842 at epoch 40\n",
            "epoch 59 average arch loss: 0.6274, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 60/80\n",
            "learning rate is set to 0.0125\n",
            "[2022-10-03 22:08:23] 1/2, train_loss: 0.3521\n",
            "[2022-10-03 22:08:26] 1/2, train_loss_arch: 0.6612\n",
            "[2022-10-03 22:08:27] 2/2, train_loss: 0.3010\n",
            "[2022-10-03 22:08:29] 2/2, train_loss_arch: 0.6194\n",
            "epoch 60 average loss: 0.3265, best mean dice: 0.5842 at epoch 40\n",
            "epoch 60 average arch loss: 0.6403, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 61/80\n",
            "learning rate is set to 0.0125\n",
            "[2022-10-03 22:08:33] 1/2, train_loss: 0.3516\n",
            "[2022-10-03 22:08:36] 1/2, train_loss_arch: 0.6117\n",
            "[2022-10-03 22:08:38] 2/2, train_loss: 0.3028\n",
            "[2022-10-03 22:08:39] 2/2, train_loss_arch: 0.6963\n",
            "epoch 61 average loss: 0.3272, best mean dice: 0.5842 at epoch 40\n",
            "epoch 61 average arch loss: 0.6540, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 62/80\n",
            "learning rate is set to 0.0125\n",
            "[2022-10-03 22:08:42] 1/2, train_loss: 0.3217\n",
            "[2022-10-03 22:08:45] 1/2, train_loss_arch: 0.6509\n",
            "[2022-10-03 22:08:46] 2/2, train_loss: 0.2928\n",
            "[2022-10-03 22:08:48] 2/2, train_loss_arch: 0.6674\n",
            "epoch 62 average loss: 0.3072, best mean dice: 0.5842 at epoch 40\n",
            "epoch 62 average arch loss: 0.6592, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 63/80\n",
            "learning rate is set to 0.0125\n",
            "[2022-10-03 22:08:50] 1/2, train_loss: 0.2727\n",
            "[2022-10-03 22:08:53] 1/2, train_loss_arch: 0.7271\n",
            "[2022-10-03 22:08:55] 2/2, train_loss: 0.3413\n",
            "[2022-10-03 22:08:56] 2/2, train_loss_arch: 0.7214\n",
            "epoch 63 average loss: 0.3070, best mean dice: 0.5842 at epoch 40\n",
            "epoch 63 average arch loss: 0.7243, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 64/80\n",
            "learning rate is set to 0.0125\n",
            "[2022-10-03 22:08:59] 1/2, train_loss: 0.3460\n",
            "[2022-10-03 22:09:01] 1/2, train_loss_arch: 0.7826\n",
            "[2022-10-03 22:09:03] 2/2, train_loss: 0.2971\n",
            "[2022-10-03 22:09:04] 2/2, train_loss_arch: 0.6554\n",
            "epoch 64 average loss: 0.3215, best mean dice: 0.5842 at epoch 40\n",
            "epoch 64 average arch loss: 0.7190, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 65/80\n",
            "learning rate is set to 0.0125\n",
            "[2022-10-03 22:09:07] 1/2, train_loss: 0.2816\n",
            "[2022-10-03 22:09:10] 1/2, train_loss_arch: 0.6816\n",
            "[2022-10-03 22:09:11] 2/2, train_loss: 0.2799\n",
            "[2022-10-03 22:09:13] 2/2, train_loss_arch: 0.7131\n",
            "epoch 65 average loss: 0.2807, best mean dice: 0.5842 at epoch 40\n",
            "epoch 65 average arch loss: 0.6973, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 66/80\n",
            "learning rate is set to 0.0125\n",
            "[2022-10-03 22:09:16] 1/2, train_loss: 0.3130\n",
            "[2022-10-03 22:09:18] 1/2, train_loss_arch: 0.6773\n",
            "[2022-10-03 22:09:20] 2/2, train_loss: 0.2888\n",
            "[2022-10-03 22:09:21] 2/2, train_loss_arch: 0.6928\n",
            "epoch 66 average loss: 0.3009, best mean dice: 0.5842 at epoch 40\n",
            "epoch 66 average arch loss: 0.6851, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 67/80\n",
            "learning rate is set to 0.0125\n",
            "[2022-10-03 22:09:24] 1/2, train_loss: 0.2929\n",
            "[2022-10-03 22:09:27] 1/2, train_loss_arch: 0.7684\n",
            "[2022-10-03 22:09:28] 2/2, train_loss: 0.4111\n",
            "[2022-10-03 22:09:29] 2/2, train_loss_arch: 0.6856\n",
            "epoch 67 average loss: 0.3520, best mean dice: 0.5842 at epoch 40\n",
            "epoch 67 average arch loss: 0.7270, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 68/80\n",
            "learning rate is set to 0.0125\n",
            "[2022-10-03 22:09:32] 1/2, train_loss: 0.3195\n",
            "[2022-10-03 22:09:35] 1/2, train_loss_arch: 0.7494\n",
            "[2022-10-03 22:09:36] 2/2, train_loss: 0.2820\n",
            "[2022-10-03 22:09:38] 2/2, train_loss_arch: 0.7324\n",
            "epoch 68 average loss: 0.3007, best mean dice: 0.5842 at epoch 40\n",
            "epoch 68 average arch loss: 0.7409, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 69/80\n",
            "learning rate is set to 0.0125\n",
            "[2022-10-03 22:09:41] 1/2, train_loss: 0.3023\n",
            "[2022-10-03 22:09:43] 1/2, train_loss_arch: 0.7382\n",
            "[2022-10-03 22:09:45] 2/2, train_loss: 0.3237\n",
            "[2022-10-03 22:09:46] 2/2, train_loss_arch: 0.7966\n",
            "epoch 69 average loss: 0.3130, best mean dice: 0.5842 at epoch 40\n",
            "epoch 69 average arch loss: 0.7674, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 70/80\n",
            "learning rate is set to 0.0125\n",
            "[2022-10-03 22:09:49] 1/2, train_loss: 0.2869\n",
            "[2022-10-03 22:09:52] 1/2, train_loss_arch: 0.7522\n",
            "[2022-10-03 22:09:53] 2/2, train_loss: 0.3787\n",
            "[2022-10-03 22:09:55] 2/2, train_loss_arch: 0.7875\n",
            "epoch 70 average loss: 0.3328, best mean dice: 0.5842 at epoch 40\n",
            "epoch 70 average arch loss: 0.7699, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 71/80\n",
            "learning rate is set to 0.0125\n",
            "[2022-10-03 22:09:58] 1/2, train_loss: 0.3125\n",
            "[2022-10-03 22:10:00] 1/2, train_loss_arch: 0.7904\n",
            "[2022-10-03 22:10:02] 2/2, train_loss: 0.3297\n",
            "[2022-10-03 22:10:03] 2/2, train_loss_arch: 0.8124\n",
            "epoch 71 average loss: 0.3211, best mean dice: 0.5842 at epoch 40\n",
            "epoch 71 average arch loss: 0.8014, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 72/80\n",
            "learning rate is set to 0.0125\n",
            "[2022-10-03 22:10:06] 1/2, train_loss: 0.2726\n",
            "[2022-10-03 22:10:09] 1/2, train_loss_arch: 0.7643\n",
            "[2022-10-03 22:10:11] 2/2, train_loss: 0.3451\n",
            "[2022-10-03 22:10:12] 2/2, train_loss_arch: 0.7516\n",
            "epoch 72 average loss: 0.3088, best mean dice: 0.5842 at epoch 40\n",
            "epoch 72 average arch loss: 0.7580, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 73/80\n",
            "learning rate is set to 0.00625\n",
            "[2022-10-03 22:10:15] 1/2, train_loss: 0.2482\n",
            "[2022-10-03 22:10:18] 1/2, train_loss_arch: 0.7905\n",
            "[2022-10-03 22:10:19] 2/2, train_loss: 0.2428\n",
            "[2022-10-03 22:10:20] 2/2, train_loss_arch: 0.7951\n",
            "epoch 73 average loss: 0.2455, best mean dice: 0.5842 at epoch 40\n",
            "epoch 73 average arch loss: 0.7928, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 74/80\n",
            "learning rate is set to 0.00625\n",
            "[2022-10-03 22:10:23] 1/2, train_loss: 0.2805\n",
            "[2022-10-03 22:10:26] 1/2, train_loss_arch: 0.7752\n",
            "[2022-10-03 22:10:27] 2/2, train_loss: 0.2546\n",
            "[2022-10-03 22:10:29] 2/2, train_loss_arch: 0.7827\n",
            "epoch 74 average loss: 0.2675, best mean dice: 0.5842 at epoch 40\n",
            "epoch 74 average arch loss: 0.7789, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 75/80\n",
            "learning rate is set to 0.00625\n",
            "[2022-10-03 22:10:32] 1/2, train_loss: 0.3544\n",
            "[2022-10-03 22:10:34] 1/2, train_loss_arch: 0.8479\n",
            "[2022-10-03 22:10:36] 2/2, train_loss: 0.3651\n",
            "[2022-10-03 22:10:37] 2/2, train_loss_arch: 0.8724\n",
            "epoch 75 average loss: 0.3597, best mean dice: 0.5842 at epoch 40\n",
            "epoch 75 average arch loss: 0.8601, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 76/80\n",
            "learning rate is set to 0.00625\n",
            "[2022-10-03 22:10:40] 1/2, train_loss: 0.2650\n",
            "[2022-10-03 22:10:43] 1/2, train_loss_arch: 0.8093\n",
            "[2022-10-03 22:10:44] 2/2, train_loss: 0.3639\n",
            "[2022-10-03 22:10:46] 2/2, train_loss_arch: 0.8614\n",
            "epoch 76 average loss: 0.3144, best mean dice: 0.5842 at epoch 40\n",
            "epoch 76 average arch loss: 0.8353, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 77/80\n",
            "learning rate is set to 0.00625\n",
            "[2022-10-03 22:10:49] 1/2, train_loss: 0.3144\n",
            "[2022-10-03 22:10:52] 1/2, train_loss_arch: 0.9429\n",
            "[2022-10-03 22:10:53] 2/2, train_loss: 0.2807\n",
            "[2022-10-03 22:10:54] 2/2, train_loss_arch: 0.8310\n",
            "epoch 77 average loss: 0.2975, best mean dice: 0.5842 at epoch 40\n",
            "epoch 77 average arch loss: 0.8870, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 78/80\n",
            "learning rate is set to 0.00625\n",
            "[2022-10-03 22:10:58] 1/2, train_loss: 0.2516\n",
            "[2022-10-03 22:11:02] 1/2, train_loss_arch: 0.8656\n",
            "[2022-10-03 22:11:03] 2/2, train_loss: 0.2994\n",
            "[2022-10-03 22:11:05] 2/2, train_loss_arch: 0.8274\n",
            "epoch 78 average loss: 0.2755, best mean dice: 0.5842 at epoch 40\n",
            "epoch 78 average arch loss: 0.8465, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 79/80\n",
            "learning rate is set to 0.00625\n",
            "[2022-10-03 22:11:08] 1/2, train_loss: 0.2668\n",
            "[2022-10-03 22:11:10] 1/2, train_loss_arch: 0.8711\n",
            "[2022-10-03 22:11:12] 2/2, train_loss: 0.2572\n",
            "[2022-10-03 22:11:13] 2/2, train_loss_arch: 0.8637\n",
            "epoch 79 average loss: 0.2620, best mean dice: 0.5842 at epoch 40\n",
            "epoch 79 average arch loss: 0.8674, best mean dice: 0.5842 at epoch 40\n",
            "----------\n",
            "epoch 80/80\n",
            "learning rate is set to 0.00625\n",
            "[2022-10-03 22:11:16] 1/2, train_loss: 0.3169\n",
            "[2022-10-03 22:11:19] 1/2, train_loss_arch: 0.9129\n",
            "[2022-10-03 22:11:20] 2/2, train_loss: 0.2428\n",
            "[2022-10-03 22:11:22] 2/2, train_loss_arch: 0.9918\n",
            "epoch 80 average loss: 0.2799, best mean dice: 0.5842 at epoch 40\n",
            "epoch 80 average arch loss: 0.9523, best mean dice: 0.5842 at epoch 40\n",
            "1 / 4 tensor([[0.7842]], device='cuda:0')\n",
            "2 / 4 tensor([[0.7842]], device='cuda:0')\n",
            "3 / 4 tensor([[0.7842]], device='cuda:0')\n",
            "4 / 4 tensor([[0.7842]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.7842101454734802\n",
            "avg_metric 0.7842101454734802\n",
            "saved new best metric model\n",
            "current epoch: 80 current mean dice: 0.7842 best mean dice: 0.7842 at epoch 80\n",
            "train completed, best_metric: 0.7842 at epoch: 80\n",
            "\", stderr=b'This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "tcmalloc: large alloc 1206001664 bytes == 0xca252000 @  0x7ff57cfb3001 0x7ff57a12f1af 0x7ff57a185c23 0x7ff57a186a87 0x7ff57a228823 0x58eb9c 0x51b4e6 0x5b4a3e 0x58f49e 0x51b221 0x5b41c5 0x4ba80a 0x51908c 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51740e 0x63daed 0x51b221 0x5b41c5 0x604133 0x606e06 0x606ecc 0x609aa6 0x64d332 0x64d4de 0x7ff57cbaec87 0x5b561a\n",
            "')\n",
            "2022-10-03 22:11:38,288 - INFO - Launching: python /content/helloworld_work_dir/dints_0/scripts/train.py run --config_file='/content/helloworld_work_dir/dints_0/configs/network_search.yaml','/content/helloworld_work_dir/dints_0/configs/transforms_train.yaml','/content/helloworld_work_dir/dints_0/configs/hyper_parameters_search.yaml','/content/helloworld_work_dir/dints_0/configs/transforms_infer.yaml','/content/helloworld_work_dir/dints_0/configs/network.yaml','/content/helloworld_work_dir/dints_0/configs/hyper_parameters.yaml','/content/helloworld_work_dir/dints_0/configs/transforms_validate.yaml' --training#num_iterations=160 --training#num_iterations_per_validation=80 --training#num_images_per_batch=2 --training#num_epochs=40 --training#num_warmup_iterations=80\n",
            "2022-10-03 22:15:11,908 - INFO - CompletedProcess(args=['python', '/content/helloworld_work_dir/dints_0/scripts/train.py', 'run', \"--config_file='/content/helloworld_work_dir/dints_0/configs/network_search.yaml','/content/helloworld_work_dir/dints_0/configs/transforms_train.yaml','/content/helloworld_work_dir/dints_0/configs/hyper_parameters_search.yaml','/content/helloworld_work_dir/dints_0/configs/transforms_infer.yaml','/content/helloworld_work_dir/dints_0/configs/network.yaml','/content/helloworld_work_dir/dints_0/configs/hyper_parameters.yaml','/content/helloworld_work_dir/dints_0/configs/transforms_validate.yaml'\", '--training#num_iterations=160', '--training#num_iterations_per_validation=80', '--training#num_images_per_batch=2', '--training#num_epochs=40', '--training#num_warmup_iterations=80'], returncode=0, stdout=b\"[info] number of GPUs: 1\n",
            "[info] world_size: 1\n",
            "train_files: 8\n",
            "val_files: 4\n",
            "num_epochs 40\n",
            "num_epochs_per_validation 20\n",
            "[info] training from scratch\n",
            "[info] amp enabled\n",
            "----------\n",
            "epoch 1/40\n",
            "learning rate is set to 0.2\n",
            "[2022-10-03 22:11:52] 1/4, train_loss: 0.7492\n",
            "[2022-10-03 22:11:53] 2/4, train_loss: 0.7016\n",
            "[2022-10-03 22:11:54] 3/4, train_loss: 0.6680\n",
            "[2022-10-03 22:11:54] 4/4, train_loss: 0.6321\n",
            "epoch 1 average loss: 0.6877, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 2/40\n",
            "learning rate is set to 0.2\n",
            "[2022-10-03 22:11:56] 1/4, train_loss: 0.5965\n",
            "[2022-10-03 22:11:57] 2/4, train_loss: 0.6022\n",
            "[2022-10-03 22:11:58] 3/4, train_loss: 0.5463\n",
            "[2022-10-03 22:11:59] 4/4, train_loss: 0.4956\n",
            "epoch 2 average loss: 0.5601, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 3/40\n",
            "learning rate is set to 0.2\n",
            "[2022-10-03 22:12:01] 1/4, train_loss: 0.4707\n",
            "[2022-10-03 22:12:02] 2/4, train_loss: 0.4169\n",
            "[2022-10-03 22:12:03] 3/4, train_loss: 0.4207\n",
            "[2022-10-03 22:12:04] 4/4, train_loss: 0.3500\n",
            "epoch 3 average loss: 0.4146, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 4/40\n",
            "learning rate is set to 0.2\n",
            "[2022-10-03 22:12:06] 1/4, train_loss: 0.3066\n",
            "[2022-10-03 22:12:07] 2/4, train_loss: 0.3328\n",
            "[2022-10-03 22:12:08] 3/4, train_loss: 0.2804\n",
            "[2022-10-03 22:12:09] 4/4, train_loss: 0.2400\n",
            "epoch 4 average loss: 0.2899, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 5/40\n",
            "learning rate is set to 0.2\n",
            "[2022-10-03 22:12:11] 1/4, train_loss: 0.2271\n",
            "[2022-10-03 22:12:12] 2/4, train_loss: 0.2362\n",
            "[2022-10-03 22:12:12] 3/4, train_loss: 0.2217\n",
            "[2022-10-03 22:12:13] 4/4, train_loss: 0.1874\n",
            "epoch 5 average loss: 0.2181, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 6/40\n",
            "learning rate is set to 0.2\n",
            "[2022-10-03 22:12:16] 1/4, train_loss: 0.2441\n",
            "[2022-10-03 22:12:17] 2/4, train_loss: 0.1405\n",
            "[2022-10-03 22:12:17] 3/4, train_loss: 0.1973\n",
            "[2022-10-03 22:12:18] 4/4, train_loss: 0.1809\n",
            "epoch 6 average loss: 0.1907, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 7/40\n",
            "learning rate is set to 0.2\n",
            "[2022-10-03 22:12:20] 1/4, train_loss: 0.1682\n",
            "[2022-10-03 22:12:21] 2/4, train_loss: 0.1360\n",
            "[2022-10-03 22:12:22] 3/4, train_loss: 0.1323\n",
            "[2022-10-03 22:12:23] 4/4, train_loss: 0.1279\n",
            "epoch 7 average loss: 0.1411, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 8/40\n",
            "learning rate is set to 0.2\n",
            "[2022-10-03 22:12:25] 1/4, train_loss: 0.1401\n",
            "[2022-10-03 22:12:26] 2/4, train_loss: 0.1434\n",
            "[2022-10-03 22:12:27] 3/4, train_loss: 0.1164\n",
            "[2022-10-03 22:12:28] 4/4, train_loss: 0.1590\n",
            "epoch 8 average loss: 0.1397, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 9/40\n",
            "learning rate is set to 0.1\n",
            "[2022-10-03 22:12:30] 1/4, train_loss: 0.1225\n",
            "[2022-10-03 22:12:31] 2/4, train_loss: 0.1370\n",
            "[2022-10-03 22:12:32] 3/4, train_loss: 0.1139\n",
            "[2022-10-03 22:12:33] 4/4, train_loss: 0.1252\n",
            "epoch 9 average loss: 0.1246, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 10/40\n",
            "learning rate is set to 0.1\n",
            "[2022-10-03 22:12:35] 1/4, train_loss: 0.1049\n",
            "[2022-10-03 22:12:36] 2/4, train_loss: 0.1491\n",
            "[2022-10-03 22:12:37] 3/4, train_loss: 0.1137\n",
            "[2022-10-03 22:12:38] 4/4, train_loss: 0.1174\n",
            "epoch 10 average loss: 0.1213, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 11/40\n",
            "learning rate is set to 0.1\n",
            "[2022-10-03 22:12:40] 1/4, train_loss: 0.0866\n",
            "[2022-10-03 22:12:41] 2/4, train_loss: 0.0894\n",
            "[2022-10-03 22:12:42] 3/4, train_loss: 0.0825\n",
            "[2022-10-03 22:12:42] 4/4, train_loss: 0.0825\n",
            "epoch 11 average loss: 0.0852, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 12/40\n",
            "learning rate is set to 0.1\n",
            "[2022-10-03 22:12:45] 1/4, train_loss: 0.0982\n",
            "[2022-10-03 22:12:45] 2/4, train_loss: 0.0716\n",
            "[2022-10-03 22:12:46] 3/4, train_loss: 0.0976\n",
            "[2022-10-03 22:12:47] 4/4, train_loss: 0.0783\n",
            "epoch 12 average loss: 0.0864, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 13/40\n",
            "learning rate is set to 0.1\n",
            "[2022-10-03 22:12:49] 1/4, train_loss: 0.0686\n",
            "[2022-10-03 22:12:50] 2/4, train_loss: 0.0660\n",
            "[2022-10-03 22:12:51] 3/4, train_loss: 0.0709\n",
            "[2022-10-03 22:12:52] 4/4, train_loss: 0.0753\n",
            "epoch 13 average loss: 0.0702, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 14/40\n",
            "learning rate is set to 0.1\n",
            "[2022-10-03 22:12:54] 1/4, train_loss: 0.1164\n",
            "[2022-10-03 22:12:55] 2/4, train_loss: 0.0610\n",
            "[2022-10-03 22:12:56] 3/4, train_loss: 0.0572\n",
            "[2022-10-03 22:12:56] 4/4, train_loss: 0.0996\n",
            "epoch 14 average loss: 0.0836, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 15/40\n",
            "learning rate is set to 0.1\n",
            "[2022-10-03 22:12:59] 1/4, train_loss: 0.0753\n",
            "[2022-10-03 22:13:00] 2/4, train_loss: 0.0520\n",
            "[2022-10-03 22:13:01] 3/4, train_loss: 0.0429\n",
            "[2022-10-03 22:13:01] 4/4, train_loss: 0.1109\n",
            "epoch 15 average loss: 0.0703, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 16/40\n",
            "learning rate is set to 0.1\n",
            "[2022-10-03 22:13:04] 1/4, train_loss: 0.0798\n",
            "[2022-10-03 22:13:05] 2/4, train_loss: 0.0867\n",
            "[2022-10-03 22:13:05] 3/4, train_loss: 0.0982\n",
            "[2022-10-03 22:13:06] 4/4, train_loss: 0.0783\n",
            "epoch 16 average loss: 0.0858, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 17/40\n",
            "learning rate is set to 0.05\n",
            "[2022-10-03 22:13:08] 1/4, train_loss: 0.0647\n",
            "[2022-10-03 22:13:09] 2/4, train_loss: 0.0728\n",
            "[2022-10-03 22:13:10] 3/4, train_loss: 0.1301\n",
            "[2022-10-03 22:13:11] 4/4, train_loss: 0.0784\n",
            "epoch 17 average loss: 0.0865, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 18/40\n",
            "learning rate is set to 0.05\n",
            "[2022-10-03 22:13:13] 1/4, train_loss: 0.0599\n",
            "[2022-10-03 22:13:14] 2/4, train_loss: 0.0594\n",
            "[2022-10-03 22:13:15] 3/4, train_loss: 0.0536\n",
            "[2022-10-03 22:13:16] 4/4, train_loss: 0.0766\n",
            "epoch 18 average loss: 0.0624, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 19/40\n",
            "learning rate is set to 0.05\n",
            "[2022-10-03 22:13:18] 1/4, train_loss: 0.0741\n",
            "[2022-10-03 22:13:19] 2/4, train_loss: 0.0456\n",
            "[2022-10-03 22:13:20] 3/4, train_loss: 0.0513\n",
            "[2022-10-03 22:13:21] 4/4, train_loss: 0.0581\n",
            "epoch 19 average loss: 0.0573, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 20/40\n",
            "learning rate is set to 0.05\n",
            "[2022-10-03 22:13:23] 1/4, train_loss: 0.0867\n",
            "[2022-10-03 22:13:24] 2/4, train_loss: 0.0528\n",
            "[2022-10-03 22:13:25] 3/4, train_loss: 0.0657\n",
            "[2022-10-03 22:13:26] 4/4, train_loss: 0.0473\n",
            "epoch 20 average loss: 0.0631, best mean dice: -1.0000 at epoch -1\n",
            "1 / 4 tensor([[0.9374]], device='cuda:0')\n",
            "2 / 4 tensor([[0.9374]], device='cuda:0')\n",
            "3 / 4 tensor([[0.9374]], device='cuda:0')\n",
            "4 / 4 tensor([[0.9374]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.9373797178268433\n",
            "avg_metric 0.9373797178268433\n",
            "saved new best metric model\n",
            "current epoch: 20 current mean dice: 0.9374 best mean dice: 0.9374 at epoch 20\n",
            "----------\n",
            "epoch 21/40\n",
            "learning rate is set to 0.05\n",
            "[2022-10-03 22:13:32] 1/4, train_loss: 0.0488\n",
            "[2022-10-03 22:13:33] 2/4, train_loss: 0.0553\n",
            "[2022-10-03 22:13:34] 3/4, train_loss: 0.0507\n",
            "[2022-10-03 22:13:35] 4/4, train_loss: 0.0556\n",
            "epoch 21 average loss: 0.0526, best mean dice: 0.9374 at epoch 20\n",
            "----------\n",
            "epoch 22/40\n",
            "learning rate is set to 0.05\n",
            "[2022-10-03 22:13:37] 1/4, train_loss: 0.0437\n",
            "[2022-10-03 22:13:37] 2/4, train_loss: 0.0589\n",
            "[2022-10-03 22:13:38] 3/4, train_loss: 0.0422\n",
            "[2022-10-03 22:13:39] 4/4, train_loss: 0.0628\n",
            "epoch 22 average loss: 0.0519, best mean dice: 0.9374 at epoch 20\n",
            "----------\n",
            "epoch 23/40\n",
            "learning rate is set to 0.05\n",
            "[2022-10-03 22:13:42] 1/4, train_loss: 0.0996\n",
            "[2022-10-03 22:13:42] 2/4, train_loss: 0.0382\n",
            "[2022-10-03 22:13:43] 3/4, train_loss: 0.0547\n",
            "[2022-10-03 22:13:44] 4/4, train_loss: 0.0364\n",
            "epoch 23 average loss: 0.0572, best mean dice: 0.9374 at epoch 20\n",
            "----------\n",
            "epoch 24/40\n",
            "learning rate is set to 0.05\n",
            "[2022-10-03 22:13:46] 1/4, train_loss: 0.0363\n",
            "[2022-10-03 22:13:47] 2/4, train_loss: 0.0415\n",
            "[2022-10-03 22:13:48] 3/4, train_loss: 0.0362\n",
            "[2022-10-03 22:13:49] 4/4, train_loss: 0.0713\n",
            "epoch 24 average loss: 0.0463, best mean dice: 0.9374 at epoch 20\n",
            "----------\n",
            "epoch 25/40\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:13:51] 1/4, train_loss: 0.0342\n",
            "[2022-10-03 22:13:52] 2/4, train_loss: 0.0436\n",
            "[2022-10-03 22:13:53] 3/4, train_loss: 0.0572\n",
            "[2022-10-03 22:13:53] 4/4, train_loss: 0.0286\n",
            "epoch 25 average loss: 0.0409, best mean dice: 0.9374 at epoch 20\n",
            "----------\n",
            "epoch 26/40\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:13:56] 1/4, train_loss: 0.0287\n",
            "[2022-10-03 22:13:57] 2/4, train_loss: 0.0313\n",
            "[2022-10-03 22:13:57] 3/4, train_loss: 0.0595\n",
            "[2022-10-03 22:13:58] 4/4, train_loss: 0.0287\n",
            "epoch 26 average loss: 0.0371, best mean dice: 0.9374 at epoch 20\n",
            "----------\n",
            "epoch 27/40\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:14:00] 1/4, train_loss: 0.0303\n",
            "[2022-10-03 22:14:01] 2/4, train_loss: 0.0269\n",
            "[2022-10-03 22:14:02] 3/4, train_loss: 0.0282\n",
            "[2022-10-03 22:14:03] 4/4, train_loss: 0.0380\n",
            "epoch 27 average loss: 0.0309, best mean dice: 0.9374 at epoch 20\n",
            "----------\n",
            "epoch 28/40\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:14:05] 1/4, train_loss: 0.0325\n",
            "[2022-10-03 22:14:06] 2/4, train_loss: 0.0259\n",
            "[2022-10-03 22:14:07] 3/4, train_loss: 0.0335\n",
            "[2022-10-03 22:14:08] 4/4, train_loss: 0.0346\n",
            "epoch 28 average loss: 0.0316, best mean dice: 0.9374 at epoch 20\n",
            "----------\n",
            "epoch 29/40\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:14:10] 1/4, train_loss: 0.0398\n",
            "[2022-10-03 22:14:11] 2/4, train_loss: 0.0271\n",
            "[2022-10-03 22:14:12] 3/4, train_loss: 0.0263\n",
            "[2022-10-03 22:14:12] 4/4, train_loss: 0.0416\n",
            "epoch 29 average loss: 0.0337, best mean dice: 0.9374 at epoch 20\n",
            "----------\n",
            "epoch 30/40\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:14:16] 1/4, train_loss: 0.0473\n",
            "[2022-10-03 22:14:17] 2/4, train_loss: 0.0379\n",
            "[2022-10-03 22:14:18] 3/4, train_loss: 0.0282\n",
            "[2022-10-03 22:14:19] 4/4, train_loss: 0.0264\n",
            "epoch 30 average loss: 0.0349, best mean dice: 0.9374 at epoch 20\n",
            "----------\n",
            "epoch 31/40\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:14:21] 1/4, train_loss: 0.0398\n",
            "[2022-10-03 22:14:22] 2/4, train_loss: 0.0361\n",
            "[2022-10-03 22:14:23] 3/4, train_loss: 0.0294\n",
            "[2022-10-03 22:14:23] 4/4, train_loss: 0.0234\n",
            "epoch 31 average loss: 0.0322, best mean dice: 0.9374 at epoch 20\n",
            "----------\n",
            "epoch 32/40\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:14:26] 1/4, train_loss: 0.0387\n",
            "[2022-10-03 22:14:27] 2/4, train_loss: 0.0289\n",
            "[2022-10-03 22:14:27] 3/4, train_loss: 0.0743\n",
            "[2022-10-03 22:14:28] 4/4, train_loss: 0.1040\n",
            "epoch 32 average loss: 0.0615, best mean dice: 0.9374 at epoch 20\n",
            "----------\n",
            "epoch 33/40\n",
            "learning rate is set to 0.0125\n",
            "[2022-10-03 22:14:31] 1/4, train_loss: 0.0259\n",
            "[2022-10-03 22:14:31] 2/4, train_loss: 0.0387\n",
            "[2022-10-03 22:14:32] 3/4, train_loss: 0.0271\n",
            "[2022-10-03 22:14:33] 4/4, train_loss: 0.0240\n",
            "epoch 33 average loss: 0.0289, best mean dice: 0.9374 at epoch 20\n",
            "----------\n",
            "epoch 34/40\n",
            "learning rate is set to 0.0125\n",
            "[2022-10-03 22:14:35] 1/4, train_loss: 0.0240\n",
            "[2022-10-03 22:14:36] 2/4, train_loss: 0.0342\n",
            "[2022-10-03 22:14:37] 3/4, train_loss: 0.0223\n",
            "[2022-10-03 22:14:38] 4/4, train_loss: 0.0267\n",
            "epoch 34 average loss: 0.0268, best mean dice: 0.9374 at epoch 20\n",
            "----------\n",
            "epoch 35/40\n",
            "learning rate is set to 0.0125\n",
            "[2022-10-03 22:14:40] 1/4, train_loss: 0.0311\n",
            "[2022-10-03 22:14:41] 2/4, train_loss: 0.0229\n",
            "[2022-10-03 22:14:42] 3/4, train_loss: 0.0213\n",
            "[2022-10-03 22:14:43] 4/4, train_loss: 0.0220\n",
            "epoch 35 average loss: 0.0243, best mean dice: 0.9374 at epoch 20\n",
            "----------\n",
            "epoch 36/40\n",
            "learning rate is set to 0.0125\n",
            "[2022-10-03 22:14:45] 1/4, train_loss: 0.0210\n",
            "[2022-10-03 22:14:46] 2/4, train_loss: 0.0308\n",
            "[2022-10-03 22:14:47] 3/4, train_loss: 0.0736\n",
            "[2022-10-03 22:14:48] 4/4, train_loss: 0.0332\n",
            "epoch 36 average loss: 0.0397, best mean dice: 0.9374 at epoch 20\n",
            "----------\n",
            "epoch 37/40\n",
            "learning rate is set to 0.0125\n",
            "[2022-10-03 22:14:50] 1/4, train_loss: 0.0230\n",
            "[2022-10-03 22:14:51] 2/4, train_loss: 0.0394\n",
            "[2022-10-03 22:14:52] 3/4, train_loss: 0.0630\n",
            "[2022-10-03 22:14:52] 4/4, train_loss: 0.0218\n",
            "epoch 37 average loss: 0.0368, best mean dice: 0.9374 at epoch 20\n",
            "----------\n",
            "epoch 38/40\n",
            "learning rate is set to 0.0125\n",
            "[2022-10-03 22:14:54] 1/4, train_loss: 0.0222\n",
            "[2022-10-03 22:14:55] 2/4, train_loss: 0.0438\n",
            "[2022-10-03 22:14:56] 3/4, train_loss: 0.0509\n",
            "[2022-10-03 22:14:57] 4/4, train_loss: 0.0216\n",
            "epoch 38 average loss: 0.0346, best mean dice: 0.9374 at epoch 20\n",
            "----------\n",
            "epoch 39/40\n",
            "learning rate is set to 0.0125\n",
            "[2022-10-03 22:14:59] 1/4, train_loss: 0.0220\n",
            "[2022-10-03 22:15:00] 2/4, train_loss: 0.0210\n",
            "[2022-10-03 22:15:01] 3/4, train_loss: 0.0199\n",
            "[2022-10-03 22:15:02] 4/4, train_loss: 0.0488\n",
            "epoch 39 average loss: 0.0279, best mean dice: 0.9374 at epoch 20\n",
            "----------\n",
            "epoch 40/40\n",
            "learning rate is set to 0.0125\n",
            "[2022-10-03 22:15:04] 1/4, train_loss: 0.0289\n",
            "[2022-10-03 22:15:05] 2/4, train_loss: 0.0226\n",
            "[2022-10-03 22:15:06] 3/4, train_loss: 0.0219\n",
            "[2022-10-03 22:15:07] 4/4, train_loss: 0.0191\n",
            "epoch 40 average loss: 0.0231, best mean dice: 0.9374 at epoch 20\n",
            "1 / 4 tensor([[0.9715]], device='cuda:0')\n",
            "2 / 4 tensor([[0.9715]], device='cuda:0')\n",
            "3 / 4 tensor([[0.9715]], device='cuda:0')\n",
            "4 / 4 tensor([[0.9715]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.9715409874916077\n",
            "avg_metric 0.9715409874916077\n",
            "saved new best metric model\n",
            "current epoch: 40 current mean dice: 0.9715 best mean dice: 0.9715 at epoch 40\n",
            "train completed, best_metric: 0.9715 at epoch: 40\n",
            "0.9715409874916077\n",
            "\", stderr=b'This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "')\n",
            "2022-10-03 22:15:11,922 - INFO - Launching: python /content/helloworld_work_dir/segresnet2d_0/scripts/train.py run --config_file='/content/helloworld_work_dir/segresnet2d_0/configs/transforms_train.yaml','/content/helloworld_work_dir/segresnet2d_0/configs/transforms_infer.yaml','/content/helloworld_work_dir/segresnet2d_0/configs/network.yaml','/content/helloworld_work_dir/segresnet2d_0/configs/hyper_parameters.yaml','/content/helloworld_work_dir/segresnet2d_0/configs/transforms_validate.yaml' --num_iterations=160 --num_iterations_per_validation=80 --num_images_per_batch=2 --num_epochs=40 --num_warmup_iterations=80\n",
            "2022-10-03 22:16:37,174 - INFO - CompletedProcess(args=['python', '/content/helloworld_work_dir/segresnet2d_0/scripts/train.py', 'run', \"--config_file='/content/helloworld_work_dir/segresnet2d_0/configs/transforms_train.yaml','/content/helloworld_work_dir/segresnet2d_0/configs/transforms_infer.yaml','/content/helloworld_work_dir/segresnet2d_0/configs/network.yaml','/content/helloworld_work_dir/segresnet2d_0/configs/hyper_parameters.yaml','/content/helloworld_work_dir/segresnet2d_0/configs/transforms_validate.yaml'\", '--num_iterations=160', '--num_iterations_per_validation=80', '--num_images_per_batch=2', '--num_epochs=40', '--num_warmup_iterations=80'], returncode=0, stdout=b\"[info] number of GPUs: 1\n",
            "[info] world_size: 1\n",
            "train_files: 8\n",
            "val_files: 4\n",
            "num_epochs 40\n",
            "num_epochs_per_validation 20\n",
            "[info] training from scratch\n",
            "[info] amp enabled\n",
            "----------\n",
            "epoch 1/40\n",
            "learning rate is set to 0.2\n",
            "[2022-10-03 22:15:23] 1/4, train_loss: 0.7660\n",
            "[2022-10-03 22:15:23] 2/4, train_loss: 0.6493\n",
            "[2022-10-03 22:15:24] 3/4, train_loss: 0.5405\n",
            "[2022-10-03 22:15:24] 4/4, train_loss: 0.3480\n",
            "epoch 1 average loss: 0.5760, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 2/40\n",
            "learning rate is set to 0.2\n",
            "[2022-10-03 22:15:25] 1/4, train_loss: 0.2957\n",
            "[2022-10-03 22:15:25] 2/4, train_loss: 0.2730\n",
            "[2022-10-03 22:15:25] 3/4, train_loss: 0.2555\n",
            "[2022-10-03 22:15:25] 4/4, train_loss: 0.3009\n",
            "epoch 2 average loss: 0.2813, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 3/40\n",
            "learning rate is set to 0.2\n",
            "[2022-10-03 22:15:26] 1/4, train_loss: 0.2364\n",
            "[2022-10-03 22:15:26] 2/4, train_loss: 0.2312\n",
            "[2022-10-03 22:15:27] 3/4, train_loss: 0.2922\n",
            "[2022-10-03 22:15:27] 4/4, train_loss: 0.1991\n",
            "epoch 3 average loss: 0.2397, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 4/40\n",
            "learning rate is set to 0.2\n",
            "[2022-10-03 22:15:28] 1/4, train_loss: 0.2877\n",
            "[2022-10-03 22:15:28] 2/4, train_loss: 0.2259\n",
            "[2022-10-03 22:15:28] 3/4, train_loss: 0.2921\n",
            "[2022-10-03 22:15:28] 4/4, train_loss: 0.2023\n",
            "epoch 4 average loss: 0.2520, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 5/40\n",
            "learning rate is set to 0.2\n",
            "[2022-10-03 22:15:30] 1/4, train_loss: 0.2309\n",
            "[2022-10-03 22:15:30] 2/4, train_loss: 0.1827\n",
            "[2022-10-03 22:15:30] 3/4, train_loss: 0.2619\n",
            "[2022-10-03 22:15:30] 4/4, train_loss: 0.1999\n",
            "epoch 5 average loss: 0.2188, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 6/40\n",
            "learning rate is set to 0.2\n",
            "[2022-10-03 22:15:31] 1/4, train_loss: 0.2801\n",
            "[2022-10-03 22:15:31] 2/4, train_loss: 0.2286\n",
            "[2022-10-03 22:15:32] 3/4, train_loss: 0.0782\n",
            "[2022-10-03 22:15:32] 4/4, train_loss: 0.2260\n",
            "epoch 6 average loss: 0.2032, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 7/40\n",
            "learning rate is set to 0.2\n",
            "[2022-10-03 22:15:33] 1/4, train_loss: 0.2587\n",
            "[2022-10-03 22:15:33] 2/4, train_loss: 0.2587\n",
            "[2022-10-03 22:15:33] 3/4, train_loss: 0.1766\n",
            "[2022-10-03 22:15:33] 4/4, train_loss: 0.5470\n",
            "epoch 7 average loss: 0.3103, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 8/40\n",
            "learning rate is set to 0.2\n",
            "[2022-10-03 22:15:34] 1/4, train_loss: 0.1897\n",
            "[2022-10-03 22:15:34] 2/4, train_loss: 0.2326\n",
            "[2022-10-03 22:15:35] 3/4, train_loss: 0.1403\n",
            "[2022-10-03 22:15:35] 4/4, train_loss: 0.1783\n",
            "epoch 8 average loss: 0.1852, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 9/40\n",
            "learning rate is set to 0.1\n",
            "[2022-10-03 22:15:36] 1/4, train_loss: 0.1824\n",
            "[2022-10-03 22:15:36] 2/4, train_loss: 0.1945\n",
            "[2022-10-03 22:15:36] 3/4, train_loss: 0.1737\n",
            "[2022-10-03 22:15:36] 4/4, train_loss: 0.1476\n",
            "epoch 9 average loss: 0.1746, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 10/40\n",
            "learning rate is set to 0.1\n",
            "[2022-10-03 22:15:38] 1/4, train_loss: 0.1890\n",
            "[2022-10-03 22:15:38] 2/4, train_loss: 0.1283\n",
            "[2022-10-03 22:15:38] 3/4, train_loss: 0.1712\n",
            "[2022-10-03 22:15:38] 4/4, train_loss: 0.1342\n",
            "epoch 10 average loss: 0.1556, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 11/40\n",
            "learning rate is set to 0.1\n",
            "[2022-10-03 22:15:39] 1/4, train_loss: 0.1040\n",
            "[2022-10-03 22:15:39] 2/4, train_loss: 0.1422\n",
            "[2022-10-03 22:15:40] 3/4, train_loss: 0.1647\n",
            "[2022-10-03 22:15:40] 4/4, train_loss: 0.1541\n",
            "epoch 11 average loss: 0.1412, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 12/40\n",
            "learning rate is set to 0.1\n",
            "[2022-10-03 22:15:41] 1/4, train_loss: 0.1041\n",
            "[2022-10-03 22:15:41] 2/4, train_loss: 0.1902\n",
            "[2022-10-03 22:15:41] 3/4, train_loss: 0.1117\n",
            "[2022-10-03 22:15:41] 4/4, train_loss: 0.2245\n",
            "epoch 12 average loss: 0.1576, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 13/40\n",
            "learning rate is set to 0.1\n",
            "[2022-10-03 22:15:43] 1/4, train_loss: 0.1390\n",
            "[2022-10-03 22:15:43] 2/4, train_loss: 0.1948\n",
            "[2022-10-03 22:15:43] 3/4, train_loss: 0.1620\n",
            "[2022-10-03 22:15:43] 4/4, train_loss: 0.1725\n",
            "epoch 13 average loss: 0.1671, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 14/40\n",
            "learning rate is set to 0.1\n",
            "[2022-10-03 22:15:44] 1/4, train_loss: 0.1523\n",
            "[2022-10-03 22:15:44] 2/4, train_loss: 0.0902\n",
            "[2022-10-03 22:15:44] 3/4, train_loss: 0.1531\n",
            "[2022-10-03 22:15:45] 4/4, train_loss: 0.1674\n",
            "epoch 14 average loss: 0.1407, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 15/40\n",
            "learning rate is set to 0.1\n",
            "[2022-10-03 22:15:46] 1/4, train_loss: 0.4567\n",
            "[2022-10-03 22:15:46] 2/4, train_loss: 0.1556\n",
            "[2022-10-03 22:15:46] 3/4, train_loss: 0.1478\n",
            "[2022-10-03 22:15:46] 4/4, train_loss: 0.0748\n",
            "epoch 15 average loss: 0.2087, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 16/40\n",
            "learning rate is set to 0.1\n",
            "[2022-10-03 22:15:47] 1/4, train_loss: 0.1221\n",
            "[2022-10-03 22:15:48] 2/4, train_loss: 0.0611\n",
            "[2022-10-03 22:15:48] 3/4, train_loss: 0.0565\n",
            "[2022-10-03 22:15:48] 4/4, train_loss: 0.0797\n",
            "epoch 16 average loss: 0.0798, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 17/40\n",
            "learning rate is set to 0.05\n",
            "[2022-10-03 22:15:49] 1/4, train_loss: 0.1505\n",
            "[2022-10-03 22:15:49] 2/4, train_loss: 0.1816\n",
            "[2022-10-03 22:15:49] 3/4, train_loss: 0.1267\n",
            "[2022-10-03 22:15:49] 4/4, train_loss: 0.0242\n",
            "epoch 17 average loss: 0.1207, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 18/40\n",
            "learning rate is set to 0.05\n",
            "[2022-10-03 22:15:51] 1/4, train_loss: 0.1726\n",
            "[2022-10-03 22:15:51] 2/4, train_loss: 0.1283\n",
            "[2022-10-03 22:15:51] 3/4, train_loss: 0.1949\n",
            "[2022-10-03 22:15:51] 4/4, train_loss: 0.1779\n",
            "epoch 18 average loss: 0.1684, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 19/40\n",
            "learning rate is set to 0.05\n",
            "[2022-10-03 22:15:53] 1/4, train_loss: 0.1549\n",
            "[2022-10-03 22:15:53] 2/4, train_loss: 0.0845\n",
            "[2022-10-03 22:15:53] 3/4, train_loss: 0.0235\n",
            "[2022-10-03 22:15:53] 4/4, train_loss: 0.0858\n",
            "epoch 19 average loss: 0.0872, best mean dice: -1.0000 at epoch -1\n",
            "----------\n",
            "epoch 20/40\n",
            "learning rate is set to 0.05\n",
            "[2022-10-03 22:15:55] 1/4, train_loss: 0.0646\n",
            "[2022-10-03 22:15:55] 2/4, train_loss: 0.1375\n",
            "[2022-10-03 22:15:56] 3/4, train_loss: 0.0780\n",
            "[2022-10-03 22:15:56] 4/4, train_loss: 0.1198\n",
            "epoch 20 average loss: 0.1000, best mean dice: -1.0000 at epoch -1\n",
            "1 / 4 tensor([[0.8616]], device='cuda:0')\n",
            "2 / 4 tensor([[0.8616]], device='cuda:0')\n",
            "3 / 4 tensor([[0.8616]], device='cuda:0')\n",
            "4 / 4 tensor([[0.8616]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.8616108894348145\n",
            "avg_metric 0.8616108894348145\n",
            "saved new best metric model\n",
            "current epoch: 20 current mean dice: 0.8616 best mean dice: 0.8616 at epoch 20\n",
            "----------\n",
            "epoch 21/40\n",
            "learning rate is set to 0.05\n",
            "[2022-10-03 22:16:01] 1/4, train_loss: 0.1326\n",
            "[2022-10-03 22:16:01] 2/4, train_loss: 0.1630\n",
            "[2022-10-03 22:16:01] 3/4, train_loss: 0.1121\n",
            "[2022-10-03 22:16:01] 4/4, train_loss: 0.1524\n",
            "epoch 21 average loss: 0.1400, best mean dice: 0.8616 at epoch 20\n",
            "----------\n",
            "epoch 22/40\n",
            "learning rate is set to 0.05\n",
            "[2022-10-03 22:16:02] 1/4, train_loss: 0.1173\n",
            "[2022-10-03 22:16:02] 2/4, train_loss: 0.0578\n",
            "[2022-10-03 22:16:03] 3/4, train_loss: 0.0823\n",
            "[2022-10-03 22:16:03] 4/4, train_loss: 0.1070\n",
            "epoch 22 average loss: 0.0911, best mean dice: 0.8616 at epoch 20\n",
            "----------\n",
            "epoch 23/40\n",
            "learning rate is set to 0.05\n",
            "[2022-10-03 22:16:04] 1/4, train_loss: 0.0576\n",
            "[2022-10-03 22:16:04] 2/4, train_loss: 0.0534\n",
            "[2022-10-03 22:16:04] 3/4, train_loss: 0.0450\n",
            "[2022-10-03 22:16:04] 4/4, train_loss: 0.0779\n",
            "epoch 23 average loss: 0.0585, best mean dice: 0.8616 at epoch 20\n",
            "----------\n",
            "epoch 24/40\n",
            "learning rate is set to 0.05\n",
            "[2022-10-03 22:16:06] 1/4, train_loss: 0.0274\n",
            "[2022-10-03 22:16:06] 2/4, train_loss: 0.1471\n",
            "[2022-10-03 22:16:06] 3/4, train_loss: 0.0988\n",
            "[2022-10-03 22:16:06] 4/4, train_loss: 0.1050\n",
            "epoch 24 average loss: 0.0946, best mean dice: 0.8616 at epoch 20\n",
            "----------\n",
            "epoch 25/40\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:16:07] 1/4, train_loss: 0.1901\n",
            "[2022-10-03 22:16:07] 2/4, train_loss: 0.1606\n",
            "[2022-10-03 22:16:07] 3/4, train_loss: 0.1375\n",
            "[2022-10-03 22:16:07] 4/4, train_loss: 0.1484\n",
            "epoch 25 average loss: 0.1591, best mean dice: 0.8616 at epoch 20\n",
            "----------\n",
            "epoch 26/40\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:16:09] 1/4, train_loss: 0.1108\n",
            "[2022-10-03 22:16:09] 2/4, train_loss: 0.0532\n",
            "[2022-10-03 22:16:09] 3/4, train_loss: 0.1391\n",
            "[2022-10-03 22:16:09] 4/4, train_loss: 0.0924\n",
            "epoch 26 average loss: 0.0989, best mean dice: 0.8616 at epoch 20\n",
            "----------\n",
            "epoch 27/40\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:16:10] 1/4, train_loss: 0.2222\n",
            "[2022-10-03 22:16:10] 2/4, train_loss: 0.1051\n",
            "[2022-10-03 22:16:11] 3/4, train_loss: 0.1040\n",
            "[2022-10-03 22:16:11] 4/4, train_loss: 0.1007\n",
            "epoch 27 average loss: 0.1330, best mean dice: 0.8616 at epoch 20\n",
            "----------\n",
            "epoch 28/40\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:16:12] 1/4, train_loss: 0.0790\n",
            "[2022-10-03 22:16:12] 2/4, train_loss: 0.0257\n",
            "[2022-10-03 22:16:12] 3/4, train_loss: 0.0992\n",
            "[2022-10-03 22:16:12] 4/4, train_loss: 0.0249\n",
            "epoch 28 average loss: 0.0572, best mean dice: 0.8616 at epoch 20\n",
            "----------\n",
            "epoch 29/40\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:16:14] 1/4, train_loss: 0.1432\n",
            "[2022-10-03 22:16:14] 2/4, train_loss: 0.1058\n",
            "[2022-10-03 22:16:14] 3/4, train_loss: 0.1365\n",
            "[2022-10-03 22:16:14] 4/4, train_loss: 0.0702\n",
            "epoch 29 average loss: 0.1139, best mean dice: 0.8616 at epoch 20\n",
            "----------\n",
            "epoch 30/40\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:16:15] 1/4, train_loss: 0.1078\n",
            "[2022-10-03 22:16:15] 2/4, train_loss: 0.0429\n",
            "[2022-10-03 22:16:16] 3/4, train_loss: 0.0953\n",
            "[2022-10-03 22:16:16] 4/4, train_loss: 0.0300\n",
            "epoch 30 average loss: 0.0690, best mean dice: 0.8616 at epoch 20\n",
            "----------\n",
            "epoch 31/40\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:16:17] 1/4, train_loss: 0.1390\n",
            "[2022-10-03 22:16:17] 2/4, train_loss: 0.0936\n",
            "[2022-10-03 22:16:17] 3/4, train_loss: 0.0305\n",
            "[2022-10-03 22:16:17] 4/4, train_loss: 0.0868\n",
            "epoch 31 average loss: 0.0875, best mean dice: 0.8616 at epoch 20\n",
            "----------\n",
            "epoch 32/40\n",
            "learning rate is set to 0.025\n",
            "[2022-10-03 22:16:19] 1/4, train_loss: 0.0714\n",
            "[2022-10-03 22:16:19] 2/4, train_loss: 0.1103\n",
            "[2022-10-03 22:16:19] 3/4, train_loss: 0.0976\n",
            "[2022-10-03 22:16:19] 4/4, train_loss: 0.2198\n",
            "epoch 32 average loss: 0.1248, best mean dice: 0.8616 at epoch 20\n",
            "----------\n",
            "epoch 33/40\n",
            "learning rate is set to 0.0125\n",
            "[2022-10-03 22:16:20] 1/4, train_loss: 0.0995\n",
            "[2022-10-03 22:16:20] 2/4, train_loss: 0.1556\n",
            "[2022-10-03 22:16:20] 3/4, train_loss: 0.0678\n",
            "[2022-10-03 22:16:20] 4/4, train_loss: 0.1056\n",
            "epoch 33 average loss: 0.1071, best mean dice: 0.8616 at epoch 20\n",
            "----------\n",
            "epoch 34/40\n",
            "learning rate is set to 0.0125\n",
            "[2022-10-03 22:16:22] 1/4, train_loss: 0.0689\n",
            "[2022-10-03 22:16:22] 2/4, train_loss: 0.1198\n",
            "[2022-10-03 22:16:22] 3/4, train_loss: 0.0467\n",
            "[2022-10-03 22:16:22] 4/4, train_loss: 0.0915\n",
            "epoch 34 average loss: 0.0817, best mean dice: 0.8616 at epoch 20\n",
            "----------\n",
            "epoch 35/40\n",
            "learning rate is set to 0.0125\n",
            "[2022-10-03 22:16:23] 1/4, train_loss: 0.0758\n",
            "[2022-10-03 22:16:23] 2/4, train_loss: 0.1212\n",
            "[2022-10-03 22:16:24] 3/4, train_loss: 0.0664\n",
            "[2022-10-03 22:16:24] 4/4, train_loss: 0.1583\n",
            "epoch 35 average loss: 0.1054, best mean dice: 0.8616 at epoch 20\n",
            "----------\n",
            "epoch 36/40\n",
            "learning rate is set to 0.0125\n",
            "[2022-10-03 22:16:25] 1/4, train_loss: 0.0428\n",
            "[2022-10-03 22:16:25] 2/4, train_loss: 0.1013\n",
            "[2022-10-03 22:16:25] 3/4, train_loss: 0.0693\n",
            "[2022-10-03 22:16:25] 4/4, train_loss: 0.1601\n",
            "epoch 36 average loss: 0.0934, best mean dice: 0.8616 at epoch 20\n",
            "----------\n",
            "epoch 37/40\n",
            "learning rate is set to 0.0125\n",
            "[2022-10-03 22:16:27] 1/4, train_loss: 0.0895\n",
            "[2022-10-03 22:16:27] 2/4, train_loss: 0.0576\n",
            "[2022-10-03 22:16:27] 3/4, train_loss: 0.0445\n",
            "[2022-10-03 22:16:27] 4/4, train_loss: 0.0410\n",
            "epoch 37 average loss: 0.0581, best mean dice: 0.8616 at epoch 20\n",
            "----------\n",
            "epoch 38/40\n",
            "learning rate is set to 0.0125\n",
            "[2022-10-03 22:16:28] 1/4, train_loss: 0.0615\n",
            "[2022-10-03 22:16:28] 2/4, train_loss: 0.0954\n",
            "[2022-10-03 22:16:28] 3/4, train_loss: 0.1049\n",
            "[2022-10-03 22:16:28] 4/4, train_loss: 0.1355\n",
            "epoch 38 average loss: 0.0993, best mean dice: 0.8616 at epoch 20\n",
            "----------\n",
            "epoch 39/40\n",
            "learning rate is set to 0.0125\n",
            "[2022-10-03 22:16:30] 1/4, train_loss: 0.1097\n",
            "[2022-10-03 22:16:30] 2/4, train_loss: 0.1157\n",
            "[2022-10-03 22:16:30] 3/4, train_loss: 0.1181\n",
            "[2022-10-03 22:16:30] 4/4, train_loss: 0.1156\n",
            "epoch 39 average loss: 0.1148, best mean dice: 0.8616 at epoch 20\n",
            "----------\n",
            "epoch 40/40\n",
            "learning rate is set to 0.0125\n",
            "[2022-10-03 22:16:31] 1/4, train_loss: 0.0470\n",
            "[2022-10-03 22:16:32] 2/4, train_loss: 0.2008\n",
            "[2022-10-03 22:16:32] 3/4, train_loss: 0.1173\n",
            "[2022-10-03 22:16:32] 4/4, train_loss: 0.0361\n",
            "epoch 40 average loss: 0.1003, best mean dice: 0.8616 at epoch 20\n",
            "1 / 4 tensor([[0.8893]], device='cuda:0')\n",
            "2 / 4 tensor([[0.8893]], device='cuda:0')\n",
            "3 / 4 tensor([[0.8893]], device='cuda:0')\n",
            "4 / 4 tensor([[0.8893]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.889339029788971\n",
            "avg_metric 0.889339029788971\n",
            "saved new best metric model\n",
            "current epoch: 40 current mean dice: 0.8893 best mean dice: 0.8893 at epoch 40\n",
            "train completed, best_metric: 0.8893 at epoch: 40\n",
            "0.889339029788971\n",
            "\", stderr=b'This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "')\n",
            "2022-10-03 22:16:37,193 - INFO - Launching: python /content/helloworld_work_dir/segresnet_0/scripts/train.py run --config_file='/content/helloworld_work_dir/segresnet_0/configs/transforms_train.yaml','/content/helloworld_work_dir/segresnet_0/configs/transforms_infer.yaml','/content/helloworld_work_dir/segresnet_0/configs/network.yaml','/content/helloworld_work_dir/segresnet_0/configs/hyper_parameters.yaml','/content/helloworld_work_dir/segresnet_0/configs/transforms_validate.yaml' --num_iterations=160 --num_iterations_per_validation=80 --num_images_per_batch=2 --num_epochs=40 --num_warmup_iterations=80\n",
            "2022-10-03 22:18:45,559 - INFO - CompletedProcess(args=['python', '/content/helloworld_work_dir/segresnet_0/scripts/train.py', 'run', \"--config_file='/content/helloworld_work_dir/segresnet_0/configs/transforms_train.yaml','/content/helloworld_work_dir/segresnet_0/configs/transforms_infer.yaml','/content/helloworld_work_dir/segresnet_0/configs/network.yaml','/content/helloworld_work_dir/segresnet_0/configs/hyper_parameters.yaml','/content/helloworld_work_dir/segresnet_0/configs/transforms_validate.yaml'\", '--num_iterations=160', '--num_iterations_per_validation=80', '--num_images_per_batch=2', '--num_epochs=40', '--num_warmup_iterations=80'], returncode=0, stdout=b\"[info] number of GPUs: 1\n",
            "[info] world_size: 1\n",
            "train_files: 8\n",
            "val_files: 4\n",
            "num_epochs 40\n",
            "num_epochs_per_validation 1\n",
            "[info] training from scratch\n",
            "[info] amp enabled\n",
            "----------\n",
            "epoch 1/40\n",
            "learning rate is set to 2e-05\n",
            "[2022-10-03 22:16:49] 1/4, train_loss: 1.2817\n",
            "[2022-10-03 22:16:49] 2/4, train_loss: 1.2560\n",
            "[2022-10-03 22:16:50] 3/4, train_loss: 1.2612\n",
            "[2022-10-03 22:16:50] 4/4, train_loss: 1.2258\n",
            "epoch 1 average loss: 1.2562, best mean dice: -1.0000 at epoch -1\n",
            "1 / 4 tensor([[0.2336]], device='cuda:0')\n",
            "2 / 4 tensor([[0.2336]], device='cuda:0')\n",
            "3 / 4 tensor([[0.2336]], device='cuda:0')\n",
            "4 / 4 tensor([[0.2336]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.23360584676265717\n",
            "avg_metric 0.23360584676265717\n",
            "saved new best metric model\n",
            "current epoch: 1 current mean dice: 0.2336 best mean dice: 0.2336 at epoch 1\n",
            "----------\n",
            "epoch 2/40\n",
            "learning rate is set to 7.538461538461539e-05\n",
            "[2022-10-03 22:16:52] 1/4, train_loss: 1.2447\n",
            "[2022-10-03 22:16:52] 2/4, train_loss: 1.1891\n",
            "[2022-10-03 22:16:53] 3/4, train_loss: 1.1810\n",
            "[2022-10-03 22:16:53] 4/4, train_loss: 1.1395\n",
            "epoch 2 average loss: 1.1886, best mean dice: 0.2336 at epoch 1\n",
            "1 / 4 tensor([[0.4788]], device='cuda:0')\n",
            "2 / 4 tensor([[0.4788]], device='cuda:0')\n",
            "3 / 4 tensor([[0.4788]], device='cuda:0')\n",
            "4 / 4 tensor([[0.4788]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.4787531793117523\n",
            "avg_metric 0.4787531793117523\n",
            "saved new best metric model\n",
            "current epoch: 2 current mean dice: 0.4788 best mean dice: 0.4788 at epoch 2\n",
            "----------\n",
            "epoch 3/40\n",
            "learning rate is set to 0.00013076923076923077\n",
            "[2022-10-03 22:16:56] 1/4, train_loss: 1.1324\n",
            "[2022-10-03 22:16:56] 2/4, train_loss: 1.1170\n",
            "[2022-10-03 22:16:56] 3/4, train_loss: 1.0916\n",
            "[2022-10-03 22:16:56] 4/4, train_loss: 1.0501\n",
            "epoch 3 average loss: 1.0978, best mean dice: 0.4788 at epoch 2\n",
            "1 / 4 tensor([[0.5739]], device='cuda:0')\n",
            "2 / 4 tensor([[0.5739]], device='cuda:0')\n",
            "3 / 4 tensor([[0.5739]], device='cuda:0')\n",
            "4 / 4 tensor([[0.5739]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.5738831162452698\n",
            "avg_metric 0.5738831162452698\n",
            "saved new best metric model\n",
            "current epoch: 3 current mean dice: 0.5739 best mean dice: 0.5739 at epoch 3\n",
            "----------\n",
            "epoch 4/40\n",
            "learning rate is set to 0.00018615384615384617\n",
            "[2022-10-03 22:16:59] 1/4, train_loss: 1.0733\n",
            "[2022-10-03 22:16:59] 2/4, train_loss: 1.0735\n",
            "[2022-10-03 22:17:00] 3/4, train_loss: 1.0464\n",
            "[2022-10-03 22:17:00] 4/4, train_loss: 1.0535\n",
            "epoch 4 average loss: 1.0617, best mean dice: 0.5739 at epoch 3\n",
            "1 / 4 tensor([[0.6781]], device='cuda:0')\n",
            "2 / 4 tensor([[0.6781]], device='cuda:0')\n",
            "3 / 4 tensor([[0.6781]], device='cuda:0')\n",
            "4 / 4 tensor([[0.6781]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.6780971884727478\n",
            "avg_metric 0.6780971884727478\n",
            "saved new best metric model\n",
            "current epoch: 4 current mean dice: 0.6781 best mean dice: 0.6781 at epoch 4\n",
            "----------\n",
            "epoch 5/40\n",
            "learning rate is set to 0.00019396926207859084\n",
            "[2022-10-03 22:17:02] 1/4, train_loss: 1.0267\n",
            "[2022-10-03 22:17:03] 2/4, train_loss: 1.0166\n",
            "[2022-10-03 22:17:03] 3/4, train_loss: 1.0155\n",
            "[2022-10-03 22:17:03] 4/4, train_loss: 0.9863\n",
            "epoch 5 average loss: 1.0113, best mean dice: 0.6781 at epoch 4\n",
            "1 / 4 tensor([[0.7162]], device='cuda:0')\n",
            "2 / 4 tensor([[0.7162]], device='cuda:0')\n",
            "3 / 4 tensor([[0.7162]], device='cuda:0')\n",
            "4 / 4 tensor([[0.7162]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.7161557674407959\n",
            "avg_metric 0.7161557674407959\n",
            "saved new best metric model\n",
            "current epoch: 5 current mean dice: 0.7162 best mean dice: 0.7162 at epoch 5\n",
            "----------\n",
            "epoch 6/40\n",
            "learning rate is set to 0.0001686241637868734\n",
            "[2022-10-03 22:17:06] 1/4, train_loss: 1.0026\n",
            "[2022-10-03 22:17:06] 2/4, train_loss: 0.9789\n",
            "[2022-10-03 22:17:06] 3/4, train_loss: 0.9732\n",
            "[2022-10-03 22:17:07] 4/4, train_loss: 0.9561\n",
            "epoch 6 average loss: 0.9777, best mean dice: 0.7162 at epoch 5\n",
            "1 / 4 tensor([[0.7172]], device='cuda:0')\n",
            "2 / 4 tensor([[0.7172]], device='cuda:0')\n",
            "3 / 4 tensor([[0.7172]], device='cuda:0')\n",
            "4 / 4 tensor([[0.7172]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.7172375321388245\n",
            "avg_metric 0.7172375321388245\n",
            "saved new best metric model\n",
            "current epoch: 6 current mean dice: 0.7172 best mean dice: 0.7172 at epoch 6\n",
            "----------\n",
            "epoch 7/40\n",
            "learning rate is set to 0.00012868032327110904\n",
            "[2022-10-03 22:17:09] 1/4, train_loss: 0.9549\n",
            "[2022-10-03 22:17:09] 2/4, train_loss: 0.9469\n",
            "[2022-10-03 22:17:10] 3/4, train_loss: 0.9335\n",
            "[2022-10-03 22:17:10] 4/4, train_loss: 0.9540\n",
            "epoch 7 average loss: 0.9473, best mean dice: 0.7172 at epoch 6\n",
            "1 / 4 tensor([[0.6991]], device='cuda:0')\n",
            "2 / 4 tensor([[0.6991]], device='cuda:0')\n",
            "3 / 4 tensor([[0.6991]], device='cuda:0')\n",
            "4 / 4 tensor([[0.6991]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.6990944147109985\n",
            "avg_metric 0.6990944147109985\n",
            "current epoch: 7 current mean dice: 0.6991 best mean dice: 0.7172 at epoch 6\n",
            "----------\n",
            "epoch 8/40\n",
            "learning rate is set to 8.263518223330697e-05\n",
            "[2022-10-03 22:17:12] 1/4, train_loss: 0.9134\n",
            "[2022-10-03 22:17:12] 2/4, train_loss: 0.9272\n",
            "[2022-10-03 22:17:12] 3/4, train_loss: 0.8969\n",
            "[2022-10-03 22:17:12] 4/4, train_loss: 0.8915\n",
            "epoch 8 average loss: 0.9073, best mean dice: 0.7172 at epoch 6\n",
            "1 / 4 tensor([[0.7094]], device='cuda:0')\n",
            "2 / 4 tensor([[0.7094]], device='cuda:0')\n",
            "3 / 4 tensor([[0.7094]], device='cuda:0')\n",
            "4 / 4 tensor([[0.7094]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.7093879580497742\n",
            "avg_metric 0.7093879580497742\n",
            "current epoch: 8 current mean dice: 0.7094 best mean dice: 0.7172 at epoch 6\n",
            "----------\n",
            "epoch 9/40\n",
            "learning rate is set to 4.028414082972141e-05\n",
            "[2022-10-03 22:17:14] 1/4, train_loss: 0.8964\n",
            "[2022-10-03 22:17:14] 2/4, train_loss: 0.8810\n",
            "[2022-10-03 22:17:14] 3/4, train_loss: 0.9043\n",
            "[2022-10-03 22:17:14] 4/4, train_loss: 0.8950\n",
            "epoch 9 average loss: 0.8942, best mean dice: 0.7172 at epoch 6\n",
            "1 / 4 tensor([[0.7115]], device='cuda:0')\n",
            "2 / 4 tensor([[0.7115]], device='cuda:0')\n",
            "3 / 4 tensor([[0.7115]], device='cuda:0')\n",
            "4 / 4 tensor([[0.7115]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.7115239500999451\n",
            "avg_metric 0.7115239500999451\n",
            "current epoch: 9 current mean dice: 0.7115 best mean dice: 0.7172 at epoch 6\n",
            "----------\n",
            "epoch 10/40\n",
            "learning rate is set to 1.0636735967658784e-05\n",
            "[2022-10-03 22:17:16] 1/4, train_loss: 0.8698\n",
            "[2022-10-03 22:17:16] 2/4, train_loss: 0.8429\n",
            "[2022-10-03 22:17:16] 3/4, train_loss: 0.8660\n",
            "[2022-10-03 22:17:17] 4/4, train_loss: 0.8663\n",
            "epoch 10 average loss: 0.8613, best mean dice: 0.7172 at epoch 6\n",
            "1 / 4 tensor([[0.7129]], device='cuda:0')\n",
            "2 / 4 tensor([[0.7129]], device='cuda:0')\n",
            "3 / 4 tensor([[0.7129]], device='cuda:0')\n",
            "4 / 4 tensor([[0.7129]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.7129310369491577\n",
            "avg_metric 0.7129310369491577\n",
            "current epoch: 10 current mean dice: 0.7129 best mean dice: 0.7172 at epoch 6\n",
            "----------\n",
            "epoch 11/40\n",
            "learning rate is set to 0.0\n",
            "[2022-10-03 22:17:18] 1/4, train_loss: 0.8508\n",
            "[2022-10-03 22:17:19] 2/4, train_loss: 0.8812\n",
            "[2022-10-03 22:17:19] 3/4, train_loss: 0.8659\n",
            "[2022-10-03 22:17:19] 4/4, train_loss: 0.8762\n",
            "epoch 11 average loss: 0.8685, best mean dice: 0.7172 at epoch 6\n",
            "1 / 4 tensor([[0.7137]], device='cuda:0')\n",
            "2 / 4 tensor([[0.7137]], device='cuda:0')\n",
            "3 / 4 tensor([[0.7137]], device='cuda:0')\n",
            "4 / 4 tensor([[0.7137]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.713685154914856\n",
            "avg_metric 0.713685154914856\n",
            "current epoch: 11 current mean dice: 0.7137 best mean dice: 0.7172 at epoch 6\n",
            "----------\n",
            "epoch 12/40\n",
            "learning rate is set to 1.0636735967658774e-05\n",
            "[2022-10-03 22:17:21] 1/4, train_loss: 0.8459\n",
            "[2022-10-03 22:17:21] 2/4, train_loss: 0.8677\n",
            "[2022-10-03 22:17:21] 3/4, train_loss: 0.8611\n",
            "[2022-10-03 22:17:21] 4/4, train_loss: 0.8562\n",
            "epoch 12 average loss: 0.8577, best mean dice: 0.7172 at epoch 6\n",
            "1 / 4 tensor([[0.7244]], device='cuda:0')\n",
            "2 / 4 tensor([[0.7244]], device='cuda:0')\n",
            "3 / 4 tensor([[0.7244]], device='cuda:0')\n",
            "4 / 4 tensor([[0.7244]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.7243607640266418\n",
            "avg_metric 0.7243607640266418\n",
            "saved new best metric model\n",
            "current epoch: 12 current mean dice: 0.7244 best mean dice: 0.7244 at epoch 12\n",
            "----------\n",
            "epoch 13/40\n",
            "learning rate is set to 4.028414082972138e-05\n",
            "[2022-10-03 22:17:24] 1/4, train_loss: 0.8563\n",
            "[2022-10-03 22:17:24] 2/4, train_loss: 0.8508\n",
            "[2022-10-03 22:17:24] 3/4, train_loss: 0.8456\n",
            "[2022-10-03 22:17:25] 4/4, train_loss: 0.8268\n",
            "epoch 13 average loss: 0.8449, best mean dice: 0.7244 at epoch 12\n",
            "1 / 4 tensor([[0.7355]], device='cuda:0')\n",
            "2 / 4 tensor([[0.7355]], device='cuda:0')\n",
            "3 / 4 tensor([[0.7355]], device='cuda:0')\n",
            "4 / 4 tensor([[0.7355]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.7354883551597595\n",
            "avg_metric 0.7354883551597595\n",
            "saved new best metric model\n",
            "current epoch: 13 current mean dice: 0.7355 best mean dice: 0.7355 at epoch 13\n",
            "----------\n",
            "epoch 14/40\n",
            "learning rate is set to 8.263518223330697e-05\n",
            "[2022-10-03 22:17:27] 1/4, train_loss: 0.8501\n",
            "[2022-10-03 22:17:28] 2/4, train_loss: 0.8233\n",
            "[2022-10-03 22:17:28] 3/4, train_loss: 0.8109\n",
            "[2022-10-03 22:17:28] 4/4, train_loss: 0.8362\n",
            "epoch 14 average loss: 0.8301, best mean dice: 0.7355 at epoch 13\n",
            "1 / 4 tensor([[0.7441]], device='cuda:0')\n",
            "2 / 4 tensor([[0.7441]], device='cuda:0')\n",
            "3 / 4 tensor([[0.7441]], device='cuda:0')\n",
            "4 / 4 tensor([[0.7441]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.7440775036811829\n",
            "avg_metric 0.7440775036811829\n",
            "saved new best metric model\n",
            "current epoch: 14 current mean dice: 0.7441 best mean dice: 0.7441 at epoch 14\n",
            "----------\n",
            "epoch 15/40\n",
            "learning rate is set to 0.00012868032327110904\n",
            "[2022-10-03 22:17:31] 1/4, train_loss: 0.8088\n",
            "[2022-10-03 22:17:31] 2/4, train_loss: 0.8135\n",
            "[2022-10-03 22:17:31] 3/4, train_loss: 0.8028\n",
            "[2022-10-03 22:17:32] 4/4, train_loss: 0.8023\n",
            "epoch 15 average loss: 0.8069, best mean dice: 0.7441 at epoch 14\n",
            "1 / 4 tensor([[0.7710]], device='cuda:0')\n",
            "2 / 4 tensor([[0.7710]], device='cuda:0')\n",
            "3 / 4 tensor([[0.7710]], device='cuda:0')\n",
            "4 / 4 tensor([[0.7710]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.7710373401641846\n",
            "avg_metric 0.7710373401641846\n",
            "saved new best metric model\n",
            "current epoch: 15 current mean dice: 0.7710 best mean dice: 0.7710 at epoch 15\n",
            "----------\n",
            "epoch 16/40\n",
            "learning rate is set to 0.0001686241637868733\n",
            "[2022-10-03 22:17:34] 1/4, train_loss: 0.7867\n",
            "[2022-10-03 22:17:35] 2/4, train_loss: 0.7832\n",
            "[2022-10-03 22:17:35] 3/4, train_loss: 0.7779\n",
            "[2022-10-03 22:17:35] 4/4, train_loss: 0.7734\n",
            "epoch 16 average loss: 0.7803, best mean dice: 0.7710 at epoch 15\n",
            "1 / 4 tensor([[0.8187]], device='cuda:0')\n",
            "2 / 4 tensor([[0.8187]], device='cuda:0')\n",
            "3 / 4 tensor([[0.8187]], device='cuda:0')\n",
            "4 / 4 tensor([[0.8187]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.8187068700790405\n",
            "avg_metric 0.8187068700790405\n",
            "saved new best metric model\n",
            "current epoch: 16 current mean dice: 0.8187 best mean dice: 0.8187 at epoch 16\n",
            "----------\n",
            "epoch 17/40\n",
            "learning rate is set to 0.00019396926207859082\n",
            "[2022-10-03 22:17:38] 1/4, train_loss: 0.7788\n",
            "[2022-10-03 22:17:38] 2/4, train_loss: 0.7622\n",
            "[2022-10-03 22:17:38] 3/4, train_loss: 0.7700\n",
            "[2022-10-03 22:17:38] 4/4, train_loss: 0.7549\n",
            "epoch 17 average loss: 0.7665, best mean dice: 0.8187 at epoch 16\n",
            "1 / 4 tensor([[0.8291]], device='cuda:0')\n",
            "2 / 4 tensor([[0.8291]], device='cuda:0')\n",
            "3 / 4 tensor([[0.8291]], device='cuda:0')\n",
            "4 / 4 tensor([[0.8291]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.8291301131248474\n",
            "avg_metric 0.8291301131248474\n",
            "saved new best metric model\n",
            "current epoch: 17 current mean dice: 0.8291 best mean dice: 0.8291 at epoch 17\n",
            "----------\n",
            "epoch 18/40\n",
            "learning rate is set to 0.00019932383577419432\n",
            "[2022-10-03 22:17:41] 1/4, train_loss: 0.7544\n",
            "[2022-10-03 22:17:41] 2/4, train_loss: 0.7581\n",
            "[2022-10-03 22:17:42] 3/4, train_loss: 0.7432\n",
            "[2022-10-03 22:17:42] 4/4, train_loss: 0.7524\n",
            "epoch 18 average loss: 0.7520, best mean dice: 0.8291 at epoch 17\n",
            "1 / 4 tensor([[0.8595]], device='cuda:0')\n",
            "2 / 4 tensor([[0.8595]], device='cuda:0')\n",
            "3 / 4 tensor([[0.8595]], device='cuda:0')\n",
            "4 / 4 tensor([[0.8595]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.8594545722007751\n",
            "avg_metric 0.8594545722007751\n",
            "saved new best metric model\n",
            "current epoch: 18 current mean dice: 0.8595 best mean dice: 0.8595 at epoch 18\n",
            "----------\n",
            "epoch 19/40\n",
            "learning rate is set to 0.0001835487811412937\n",
            "[2022-10-03 22:17:45] 1/4, train_loss: 0.7272\n",
            "[2022-10-03 22:17:45] 2/4, train_loss: 0.7337\n",
            "[2022-10-03 22:17:45] 3/4, train_loss: 0.7266\n",
            "[2022-10-03 22:17:45] 4/4, train_loss: 0.7406\n",
            "epoch 19 average loss: 0.7320, best mean dice: 0.8595 at epoch 18\n",
            "1 / 4 tensor([[0.8734]], device='cuda:0')\n",
            "2 / 4 tensor([[0.8734]], device='cuda:0')\n",
            "3 / 4 tensor([[0.8734]], device='cuda:0')\n",
            "4 / 4 tensor([[0.8734]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.8733741641044617\n",
            "avg_metric 0.8733741641044617\n",
            "saved new best metric model\n",
            "current epoch: 19 current mean dice: 0.8734 best mean dice: 0.8734 at epoch 19\n",
            "----------\n",
            "epoch 20/40\n",
            "learning rate is set to 0.00015\n",
            "[2022-10-03 22:17:48] 1/4, train_loss: 0.6907\n",
            "[2022-10-03 22:17:48] 2/4, train_loss: 0.7228\n",
            "[2022-10-03 22:17:49] 3/4, train_loss: 0.7184\n",
            "[2022-10-03 22:17:49] 4/4, train_loss: 0.7120\n",
            "epoch 20 average loss: 0.7110, best mean dice: 0.8734 at epoch 19\n",
            "1 / 4 tensor([[0.8849]], device='cuda:0')\n",
            "2 / 4 tensor([[0.8849]], device='cuda:0')\n",
            "3 / 4 tensor([[0.8849]], device='cuda:0')\n",
            "4 / 4 tensor([[0.8849]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.8848997950553894\n",
            "avg_metric 0.8848997950553894\n",
            "saved new best metric model\n",
            "current epoch: 20 current mean dice: 0.8849 best mean dice: 0.8849 at epoch 20\n",
            "----------\n",
            "epoch 21/40\n",
            "learning rate is set to 0.00010581448289104765\n",
            "[2022-10-03 22:17:53] 1/4, train_loss: 0.7216\n",
            "[2022-10-03 22:17:53] 2/4, train_loss: 0.7069\n",
            "[2022-10-03 22:17:53] 3/4, train_loss: 0.7091\n",
            "[2022-10-03 22:17:53] 4/4, train_loss: 0.7298\n",
            "epoch 21 average loss: 0.7168, best mean dice: 0.8849 at epoch 20\n",
            "1 / 4 tensor([[0.8707]], device='cuda:0')\n",
            "2 / 4 tensor([[0.8707]], device='cuda:0')\n",
            "3 / 4 tensor([[0.8707]], device='cuda:0')\n",
            "4 / 4 tensor([[0.8707]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.8706926703453064\n",
            "avg_metric 0.8706926703453064\n",
            "current epoch: 21 current mean dice: 0.8707 best mean dice: 0.8849 at epoch 20\n",
            "----------\n",
            "epoch 22/40\n",
            "learning rate is set to 6.0392023396084285e-05\n",
            "[2022-10-03 22:17:55] 1/4, train_loss: 0.7025\n",
            "[2022-10-03 22:17:55] 2/4, train_loss: 0.7021\n",
            "[2022-10-03 22:17:55] 3/4, train_loss: 0.7015\n",
            "[2022-10-03 22:17:56] 4/4, train_loss: 0.6752\n",
            "epoch 22 average loss: 0.6953, best mean dice: 0.8849 at epoch 20\n",
            "1 / 4 tensor([[0.8920]], device='cuda:0')\n",
            "2 / 4 tensor([[0.8920]], device='cuda:0')\n",
            "3 / 4 tensor([[0.8920]], device='cuda:0')\n",
            "4 / 4 tensor([[0.8920]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.8920449018478394\n",
            "avg_metric 0.8920449018478394\n",
            "saved new best metric model\n",
            "current epoch: 22 current mean dice: 0.8920 best mean dice: 0.8920 at epoch 22\n",
            "----------\n",
            "epoch 23/40\n",
            "learning rate is set to 2.339555568810228e-05\n",
            "[2022-10-03 22:17:58] 1/4, train_loss: 0.6974\n",
            "[2022-10-03 22:17:59] 2/4, train_loss: 0.6970\n",
            "[2022-10-03 22:17:59] 3/4, train_loss: 0.6994\n",
            "[2022-10-03 22:17:59] 4/4, train_loss: 0.7099\n",
            "epoch 23 average loss: 0.7009, best mean dice: 0.8920 at epoch 22\n",
            "1 / 4 tensor([[0.8897]], device='cuda:0')\n",
            "2 / 4 tensor([[0.8897]], device='cuda:0')\n",
            "3 / 4 tensor([[0.8897]], device='cuda:0')\n",
            "4 / 4 tensor([[0.8897]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.8896898031234741\n",
            "avg_metric 0.8896898031234741\n",
            "current epoch: 23 current mean dice: 0.8897 best mean dice: 0.8920 at epoch 22\n",
            "----------\n",
            "epoch 24/40\n",
            "learning rate is set to 2.6955129420176086e-06\n",
            "[2022-10-03 22:18:01] 1/4, train_loss: 0.7039\n",
            "[2022-10-03 22:18:01] 2/4, train_loss: 0.6970\n",
            "[2022-10-03 22:18:01] 3/4, train_loss: 0.7015\n",
            "[2022-10-03 22:18:01] 4/4, train_loss: 0.7041\n",
            "epoch 24 average loss: 0.7016, best mean dice: 0.8920 at epoch 22\n",
            "1 / 4 tensor([[0.8894]], device='cuda:0')\n",
            "2 / 4 tensor([[0.8894]], device='cuda:0')\n",
            "3 / 4 tensor([[0.8894]], device='cuda:0')\n",
            "4 / 4 tensor([[0.8894]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.889384925365448\n",
            "avg_metric 0.889384925365448\n",
            "current epoch: 24 current mean dice: 0.8894 best mean dice: 0.8920 at epoch 22\n",
            "----------\n",
            "epoch 25/40\n",
            "learning rate is set to 2.695512942017586e-06\n",
            "[2022-10-03 22:18:03] 1/4, train_loss: 0.6975\n",
            "[2022-10-03 22:18:03] 2/4, train_loss: 0.7024\n",
            "[2022-10-03 22:18:03] 3/4, train_loss: 0.6990\n",
            "[2022-10-03 22:18:04] 4/4, train_loss: 0.6772\n",
            "epoch 25 average loss: 0.6940, best mean dice: 0.8920 at epoch 22\n",
            "1 / 4 tensor([[0.8855]], device='cuda:0')\n",
            "2 / 4 tensor([[0.8855]], device='cuda:0')\n",
            "3 / 4 tensor([[0.8855]], device='cuda:0')\n",
            "4 / 4 tensor([[0.8855]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.8854642510414124\n",
            "avg_metric 0.8854642510414124\n",
            "current epoch: 25 current mean dice: 0.8855 best mean dice: 0.8920 at epoch 22\n",
            "----------\n",
            "epoch 26/40\n",
            "learning rate is set to 2.3395555688102235e-05\n",
            "[2022-10-03 22:18:05] 1/4, train_loss: 0.7027\n",
            "[2022-10-03 22:18:05] 2/4, train_loss: 0.6844\n",
            "[2022-10-03 22:18:06] 3/4, train_loss: 0.6961\n",
            "[2022-10-03 22:18:06] 4/4, train_loss: 0.6964\n",
            "epoch 26 average loss: 0.6949, best mean dice: 0.8920 at epoch 22\n",
            "1 / 4 tensor([[0.8847]], device='cuda:0')\n",
            "2 / 4 tensor([[0.8847]], device='cuda:0')\n",
            "3 / 4 tensor([[0.8847]], device='cuda:0')\n",
            "4 / 4 tensor([[0.8847]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.88474041223526\n",
            "avg_metric 0.88474041223526\n",
            "current epoch: 26 current mean dice: 0.8847 best mean dice: 0.8920 at epoch 22\n",
            "----------\n",
            "epoch 27/40\n",
            "learning rate is set to 6.039202339608422e-05\n",
            "[2022-10-03 22:18:08] 1/4, train_loss: 0.7085\n",
            "[2022-10-03 22:18:08] 2/4, train_loss: 0.6951\n",
            "[2022-10-03 22:18:08] 3/4, train_loss: 0.6875\n",
            "[2022-10-03 22:18:08] 4/4, train_loss: 0.6990\n",
            "epoch 27 average loss: 0.6975, best mean dice: 0.8920 at epoch 22\n",
            "1 / 4 tensor([[0.8899]], device='cuda:0')\n",
            "2 / 4 tensor([[0.8899]], device='cuda:0')\n",
            "3 / 4 tensor([[0.8899]], device='cuda:0')\n",
            "4 / 4 tensor([[0.8899]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.8898598551750183\n",
            "avg_metric 0.8898598551750183\n",
            "current epoch: 27 current mean dice: 0.8899 best mean dice: 0.8920 at epoch 22\n",
            "----------\n",
            "epoch 28/40\n",
            "learning rate is set to 0.00010581448289104765\n",
            "[2022-10-03 22:18:10] 1/4, train_loss: 0.6807\n",
            "[2022-10-03 22:18:10] 2/4, train_loss: 0.6874\n",
            "[2022-10-03 22:18:10] 3/4, train_loss: 0.6888\n",
            "[2022-10-03 22:18:10] 4/4, train_loss: 0.6843\n",
            "epoch 28 average loss: 0.6853, best mean dice: 0.8920 at epoch 22\n",
            "1 / 4 tensor([[0.9197]], device='cuda:0')\n",
            "2 / 4 tensor([[0.9197]], device='cuda:0')\n",
            "3 / 4 tensor([[0.9197]], device='cuda:0')\n",
            "4 / 4 tensor([[0.9197]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.91972416639328\n",
            "avg_metric 0.91972416639328\n",
            "saved new best metric model\n",
            "current epoch: 28 current mean dice: 0.9197 best mean dice: 0.9197 at epoch 28\n",
            "----------\n",
            "epoch 29/40\n",
            "learning rate is set to 0.0001499999999999999\n",
            "[2022-10-03 22:18:13] 1/4, train_loss: 0.6954\n",
            "[2022-10-03 22:18:13] 2/4, train_loss: 0.6710\n",
            "[2022-10-03 22:18:14] 3/4, train_loss: 0.6841\n",
            "[2022-10-03 22:18:14] 4/4, train_loss: 0.6913\n",
            "epoch 29 average loss: 0.6854, best mean dice: 0.9197 at epoch 28\n",
            "1 / 4 tensor([[0.9046]], device='cuda:0')\n",
            "2 / 4 tensor([[0.9046]], device='cuda:0')\n",
            "3 / 4 tensor([[0.9046]], device='cuda:0')\n",
            "4 / 4 tensor([[0.9046]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.9046350121498108\n",
            "avg_metric 0.9046350121498108\n",
            "current epoch: 29 current mean dice: 0.9046 best mean dice: 0.9197 at epoch 28\n",
            "----------\n",
            "epoch 30/40\n",
            "learning rate is set to 0.0001835487811412936\n",
            "[2022-10-03 22:18:15] 1/4, train_loss: 0.6762\n",
            "[2022-10-03 22:18:16] 2/4, train_loss: 0.6484\n",
            "[2022-10-03 22:18:16] 3/4, train_loss: 0.6748\n",
            "[2022-10-03 22:18:16] 4/4, train_loss: 0.6734\n",
            "epoch 30 average loss: 0.6682, best mean dice: 0.9197 at epoch 28\n",
            "1 / 4 tensor([[0.9280]], device='cuda:0')\n",
            "2 / 4 tensor([[0.9280]], device='cuda:0')\n",
            "3 / 4 tensor([[0.9280]], device='cuda:0')\n",
            "4 / 4 tensor([[0.9280]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.9280101656913757\n",
            "avg_metric 0.9280101656913757\n",
            "saved new best metric model\n",
            "current epoch: 30 current mean dice: 0.9280 best mean dice: 0.9280 at epoch 30\n",
            "----------\n",
            "epoch 31/40\n",
            "learning rate is set to 0.00019932383577419432\n",
            "[2022-10-03 22:18:19] 1/4, train_loss: 0.6794\n",
            "[2022-10-03 22:18:19] 2/4, train_loss: 0.6718\n",
            "[2022-10-03 22:18:20] 3/4, train_loss: 0.6698\n",
            "[2022-10-03 22:18:20] 4/4, train_loss: 0.6717\n",
            "epoch 31 average loss: 0.6732, best mean dice: 0.9280 at epoch 30\n",
            "1 / 4 tensor([[0.8887]], device='cuda:0')\n",
            "2 / 4 tensor([[0.8887]], device='cuda:0')\n",
            "3 / 4 tensor([[0.8887]], device='cuda:0')\n",
            "4 / 4 tensor([[0.8887]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.888687789440155\n",
            "avg_metric 0.888687789440155\n",
            "current epoch: 31 current mean dice: 0.8887 best mean dice: 0.9280 at epoch 30\n",
            "----------\n",
            "epoch 32/40\n",
            "learning rate is set to 0.00019396926207859087\n",
            "[2022-10-03 22:18:22] 1/4, train_loss: 0.6650\n",
            "[2022-10-03 22:18:22] 2/4, train_loss: 0.6580\n",
            "[2022-10-03 22:18:22] 3/4, train_loss: 0.6595\n",
            "[2022-10-03 22:18:22] 4/4, train_loss: 0.6602\n",
            "epoch 32 average loss: 0.6607, best mean dice: 0.9280 at epoch 30\n",
            "1 / 4 tensor([[0.9135]], device='cuda:0')\n",
            "2 / 4 tensor([[0.9135]], device='cuda:0')\n",
            "3 / 4 tensor([[0.9135]], device='cuda:0')\n",
            "4 / 4 tensor([[0.9135]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.9134852290153503\n",
            "avg_metric 0.9134852290153503\n",
            "current epoch: 32 current mean dice: 0.9135 best mean dice: 0.9280 at epoch 30\n",
            "----------\n",
            "epoch 33/40\n",
            "learning rate is set to 0.00016862416378687328\n",
            "[2022-10-03 22:18:25] 1/4, train_loss: 0.6536\n",
            "[2022-10-03 22:18:25] 2/4, train_loss: 0.6602\n",
            "[2022-10-03 22:18:25] 3/4, train_loss: 0.6469\n",
            "[2022-10-03 22:18:25] 4/4, train_loss: 0.6516\n",
            "epoch 33 average loss: 0.6531, best mean dice: 0.9280 at epoch 30\n",
            "1 / 4 tensor([[0.8934]], device='cuda:0')\n",
            "2 / 4 tensor([[0.8934]], device='cuda:0')\n",
            "3 / 4 tensor([[0.8934]], device='cuda:0')\n",
            "4 / 4 tensor([[0.8934]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.8933894634246826\n",
            "avg_metric 0.8933894634246826\n",
            "current epoch: 33 current mean dice: 0.8934 best mean dice: 0.9280 at epoch 30\n",
            "----------\n",
            "epoch 34/40\n",
            "learning rate is set to 0.0001286803232711091\n",
            "[2022-10-03 22:18:27] 1/4, train_loss: 0.6573\n",
            "[2022-10-03 22:18:27] 2/4, train_loss: 0.6482\n",
            "[2022-10-03 22:18:28] 3/4, train_loss: 0.6413\n",
            "[2022-10-03 22:18:28] 4/4, train_loss: 0.6813\n",
            "epoch 34 average loss: 0.6570, best mean dice: 0.9280 at epoch 30\n",
            "1 / 4 tensor([[0.9296]], device='cuda:0')\n",
            "2 / 4 tensor([[0.9296]], device='cuda:0')\n",
            "3 / 4 tensor([[0.9296]], device='cuda:0')\n",
            "4 / 4 tensor([[0.9296]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.9296103119850159\n",
            "avg_metric 0.9296103119850159\n",
            "saved new best metric model\n",
            "current epoch: 34 current mean dice: 0.9296 best mean dice: 0.9296 at epoch 34\n",
            "----------\n",
            "epoch 35/40\n",
            "learning rate is set to 8.263518223330704e-05\n",
            "[2022-10-03 22:18:31] 1/4, train_loss: 0.6363\n",
            "[2022-10-03 22:18:31] 2/4, train_loss: 0.6380\n",
            "[2022-10-03 22:18:31] 3/4, train_loss: 0.6364\n",
            "[2022-10-03 22:18:31] 4/4, train_loss: 0.6374\n",
            "epoch 35 average loss: 0.6370, best mean dice: 0.9296 at epoch 34\n",
            "1 / 4 tensor([[0.9067]], device='cuda:0')\n",
            "2 / 4 tensor([[0.9067]], device='cuda:0')\n",
            "3 / 4 tensor([[0.9067]], device='cuda:0')\n",
            "4 / 4 tensor([[0.9067]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.9066941142082214\n",
            "avg_metric 0.9066941142082214\n",
            "current epoch: 35 current mean dice: 0.9067 best mean dice: 0.9296 at epoch 34\n",
            "----------\n",
            "epoch 36/40\n",
            "learning rate is set to 4.0284140829721585e-05\n",
            "[2022-10-03 22:18:33] 1/4, train_loss: 0.6276\n",
            "[2022-10-03 22:18:33] 2/4, train_loss: 0.6357\n",
            "[2022-10-03 22:18:34] 3/4, train_loss: 0.6265\n",
            "[2022-10-03 22:18:34] 4/4, train_loss: 0.6394\n",
            "epoch 36 average loss: 0.6323, best mean dice: 0.9296 at epoch 34\n",
            "1 / 4 tensor([[0.9144]], device='cuda:0')\n",
            "2 / 4 tensor([[0.9144]], device='cuda:0')\n",
            "3 / 4 tensor([[0.9144]], device='cuda:0')\n",
            "4 / 4 tensor([[0.9144]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.9143719673156738\n",
            "avg_metric 0.9143719673156738\n",
            "current epoch: 36 current mean dice: 0.9144 best mean dice: 0.9296 at epoch 34\n",
            "----------\n",
            "epoch 37/40\n",
            "learning rate is set to 1.0636735967658806e-05\n",
            "[2022-10-03 22:18:35] 1/4, train_loss: 0.6327\n",
            "[2022-10-03 22:18:36] 2/4, train_loss: 0.6272\n",
            "[2022-10-03 22:18:36] 3/4, train_loss: 0.6546\n",
            "[2022-10-03 22:18:36] 4/4, train_loss: 0.6333\n",
            "epoch 37 average loss: 0.6369, best mean dice: 0.9296 at epoch 34\n",
            "1 / 4 tensor([[0.9173]], device='cuda:0')\n",
            "2 / 4 tensor([[0.9173]], device='cuda:0')\n",
            "3 / 4 tensor([[0.9173]], device='cuda:0')\n",
            "4 / 4 tensor([[0.9173]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.9172912836074829\n",
            "avg_metric 0.9172912836074829\n",
            "current epoch: 37 current mean dice: 0.9173 best mean dice: 0.9296 at epoch 34\n",
            "----------\n",
            "epoch 38/40\n",
            "learning rate is set to 0.0\n",
            "[2022-10-03 22:18:38] 1/4, train_loss: 0.6610\n",
            "[2022-10-03 22:18:38] 2/4, train_loss: 0.6324\n",
            "[2022-10-03 22:18:38] 3/4, train_loss: 0.6364\n",
            "[2022-10-03 22:18:38] 4/4, train_loss: 0.6335\n",
            "epoch 38 average loss: 0.6409, best mean dice: 0.9296 at epoch 34\n",
            "1 / 4 tensor([[0.9188]], device='cuda:0')\n",
            "2 / 4 tensor([[0.9188]], device='cuda:0')\n",
            "3 / 4 tensor([[0.9188]], device='cuda:0')\n",
            "4 / 4 tensor([[0.9188]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.9188383221626282\n",
            "avg_metric 0.9188383221626282\n",
            "current epoch: 38 current mean dice: 0.9188 best mean dice: 0.9296 at epoch 34\n",
            "----------\n",
            "epoch 39/40\n",
            "learning rate is set to 1.0636735967658674e-05\n",
            "[2022-10-03 22:18:40] 1/4, train_loss: 0.6385\n",
            "[2022-10-03 22:18:40] 2/4, train_loss: 0.6319\n",
            "[2022-10-03 22:18:41] 3/4, train_loss: 0.6597\n",
            "[2022-10-03 22:18:41] 4/4, train_loss: 0.6319\n",
            "epoch 39 average loss: 0.6405, best mean dice: 0.9296 at epoch 34\n",
            "1 / 4 tensor([[0.9294]], device='cuda:0')\n",
            "2 / 4 tensor([[0.9294]], device='cuda:0')\n",
            "3 / 4 tensor([[0.9294]], device='cuda:0')\n",
            "4 / 4 tensor([[0.9294]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.9293630719184875\n",
            "avg_metric 0.9293630719184875\n",
            "current epoch: 39 current mean dice: 0.9294 best mean dice: 0.9296 at epoch 34\n",
            "----------\n",
            "epoch 40/40\n",
            "learning rate is set to 4.028414082972134e-05\n",
            "[2022-10-03 22:18:42] 1/4, train_loss: 0.6306\n",
            "[2022-10-03 22:18:43] 2/4, train_loss: 0.6330\n",
            "[2022-10-03 22:18:43] 3/4, train_loss: 0.6391\n",
            "[2022-10-03 22:18:43] 4/4, train_loss: 0.6415\n",
            "epoch 40 average loss: 0.6360, best mean dice: 0.9296 at epoch 34\n",
            "1 / 4 tensor([[0.9267]], device='cuda:0')\n",
            "2 / 4 tensor([[0.9267]], device='cuda:0')\n",
            "3 / 4 tensor([[0.9267]], device='cuda:0')\n",
            "4 / 4 tensor([[0.9267]], device='cuda:0')\n",
            "evaluation metric - class 1: 0.9266902208328247\n",
            "avg_metric 0.9266902208328247\n",
            "current epoch: 40 current mean dice: 0.9267 best mean dice: 0.9296 at epoch 34\n",
            "train completed, best_metric: 0.9296 at epoch: 34\n",
            "0.9296103119850159\n",
            "\", stderr=b'This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "')\n",
            "0\n",
            "[info] checkpoint /content/helloworld_work_dir/segresnet2d_0/model_fold0/best_metric_model.pt loaded\n",
            "2022-10-03 22:18:46,894 INFO image_writer.py:194 - writing: /content/helloworld_work_dir/segresnet2d_0/prediction_testing/test_image_001/test_image_001_seg.nii.gz\n",
            "[info] checkpoint /content/helloworld_work_dir/segresnet_0/model_fold0/best_metric_model.pt loaded\n",
            "2022-10-03 22:18:48,077 INFO image_writer.py:194 - writing: /content/helloworld_work_dir/segresnet_0/prediction_testing/test_image_001/test_image_001_seg.nii.gz\n",
            "1\n",
            "[info] checkpoint /content/helloworld_work_dir/segresnet2d_0/model_fold0/best_metric_model.pt loaded\n",
            "2022-10-03 22:18:49,127 INFO image_writer.py:194 - writing: /content/helloworld_work_dir/segresnet2d_0/prediction_testing/test_image_002/test_image_002_seg.nii.gz\n",
            "[info] checkpoint /content/helloworld_work_dir/segresnet_0/model_fold0/best_metric_model.pt loaded\n",
            "2022-10-03 22:18:50,207 INFO image_writer.py:194 - writing: /content/helloworld_work_dir/segresnet_0/prediction_testing/test_image_002/test_image_002_seg.nii.gz\n",
            "2\n",
            "[info] checkpoint /content/helloworld_work_dir/segresnet2d_0/model_fold0/best_metric_model.pt loaded\n",
            "2022-10-03 22:18:51,503 INFO image_writer.py:194 - writing: /content/helloworld_work_dir/segresnet2d_0/prediction_testing/test_image_001/test_image_001_seg.nii.gz\n",
            "[info] checkpoint /content/helloworld_work_dir/segresnet_0/model_fold0/best_metric_model.pt loaded\n",
            "2022-10-03 22:18:52,575 INFO image_writer.py:194 - writing: /content/helloworld_work_dir/segresnet_0/prediction_testing/test_image_001/test_image_001_seg.nii.gz\n",
            "3\n",
            "[info] checkpoint /content/helloworld_work_dir/segresnet2d_0/model_fold0/best_metric_model.pt loaded\n",
            "2022-10-03 22:18:53,627 INFO image_writer.py:194 - writing: /content/helloworld_work_dir/segresnet2d_0/prediction_testing/test_image_002/test_image_002_seg.nii.gz\n",
            "[info] checkpoint /content/helloworld_work_dir/segresnet_0/model_fold0/best_metric_model.pt loaded\n",
            "2022-10-03 22:18:54,693 INFO image_writer.py:194 - writing: /content/helloworld_work_dir/segresnet_0/prediction_testing/test_image_002/test_image_002_seg.nii.gz\n",
            "Auto3Dseg picked the following networks to ensemble:\n",
            "segresnet2d_0\n",
            "segresnet_0\n",
            "2022-10-03 22:18:54,723 INFO image_writer.py:194 - writing: /content/helloworld_work_dir/ensemble_output/test_image_001/test_image_001_ensemble.nii.gz\n",
            "2022-10-03 22:18:54,755 INFO image_writer.py:194 - writing: /content/helloworld_work_dir/ensemble_output/test_image_002/test_image_002_ensemble.nii.gz\n",
            "2022-10-03 22:18:54,798 INFO image_writer.py:194 - writing: /content/helloworld_work_dir/ensemble_output/test_image_001/test_image_001_ensemble.nii.gz\n",
            "2022-10-03 22:18:54,822 INFO image_writer.py:194 - writing: /content/helloworld_work_dir/ensemble_output/test_image_002/test_image_002_ensemble.nii.gz\n",
            "2022-10-03 22:18:54,840 - INFO - Auto3Dseg ensemble prediction outputs are saved in /content/helloworld_work_dir/ensemble_output.\n",
            "2022-10-03 22:18:54,844 - INFO - Auto3Dseg pipeline is complete successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "image_name = sim_datalist['testing'][0]['image'].split(\".\")[0]\n",
        "prediction_nib = nib.load(os.path.join(work_dir, 'ensemble_output', image_name, image_name+\"_ensemble\"+\".nii.gz\"))\n",
        "pred = np.array(prediction_nib.dataobj)\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.imshow(img[32])\n",
        "plt.title('image')\n",
        "cbar = plt.colorbar(shrink=0.8)\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.imshow(lbl[32])\n",
        "plt.title('label')\n",
        "cbar = plt.colorbar(shrink=0.8)\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.imshow(pred[32, :, :, 0])\n",
        "plt.title('background class prediction')\n",
        "cbar = plt.colorbar(shrink=0.8)\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.imshow(pred[32, :, :, 1])\n",
        "plt.title('foreground class prediction')\n",
        "cbar = plt.colorbar(shrink=0.8)\n",
        "# set the spacing between subplots\n",
        "plt.subplots_adjust(left=0.1,\n",
        "                    bottom=0.1,\n",
        "                    right=0.9,\n",
        "                    top=0.9,\n",
        "                    wspace=0.4,\n",
        "                    hspace=0.4)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "K7Oj7lhQm2qp",
        "outputId": "4e8964a0-6019-4152-813f-33235fb5c2c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 8 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xF4gqhK3sWhe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}